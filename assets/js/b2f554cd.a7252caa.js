"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[11477],{30010:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"mikro-orm-5-released","metadata":{"permalink":"/blog/mikro-orm-5-released","source":"@site/blog/2022-02-06-mikro-orm-5-released.md","title":"MikroORM 5: Stricter, Safer, Smarter","description":"The next major version of MikroORM has been just released. The title says: Stricter, Safer, Smarter \u2013 why?","date":"2022-02-06T00:00:00.000Z","formattedDate":"February 6, 2022","tags":[{"label":"typescript","permalink":"/blog/tags/typescript"},{"label":"javascript","permalink":"/blog/tags/javascript"},{"label":"node","permalink":"/blog/tags/node"},{"label":"sql","permalink":"/blog/tags/sql"}],"readingTime":15.695,"hasTruncateMarker":false,"authors":[{"name":"Martin Ad\xe1mek","title":"Author of MikroORM","url":"https://github.com/B4nan","imageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4"}],"frontMatter":{"slug":"mikro-orm-5-released","title":"MikroORM 5: Stricter, Safer, Smarter","author":"Martin Ad\xe1mek","authorTitle":"Author of MikroORM","authorURL":"https://github.com/B4nan","authorImageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4","authorTwitter":"B4nan","tags":["typescript","javascript","node","sql"]},"nextItem":{"title":"MikroORM 4.1: Let\u2019s talk about performance","permalink":"/blog/mikro-orm-4-1-released"}},"content":"The next major version of MikroORM has been just released. The title says: Stricter, Safer, Smarter \u2013 why?\\n\\n![](https://cdn-images-1.medium.com/max/430/0*atMJ3hrlUosSpnQy.jpg)\\n\\n- Greatly improved type safety (e.g. populate and partial loading hints)\\n- Auto-flush mode (so we never lose in-memory changes)\\n- Automatic refreshing of loaded entities (say goodby to refresh: true)\\n- Reworked schema diffing with automatic down migrations support\\n- and [many many more](https://github.com/mikro-orm/mikro-orm/blob/master/CHANGELOG.md#500-rc0-2022-01-23)...\\n\\n> This time it took almost a year to get here \u2013 initial work on v5 started [back in March 2021](https://github.com/mikro-orm/mikro-orm/issues/1623).\\n\\n### In case you don\u2019t know\u2026\\n\\nIf you never heard of [MikroORM](https://github.com/mikro-orm/mikro-orm), it\u2019s a TypeScript data-mapper ORM with Unit of Work and Identity Map. It supports MongoDB, MySQL, PostgreSQL, and SQLite drivers currently. Key features of the ORM are:\\n\\n- [Implicit transactions](https://github.com/mikro-orm/mikro-orm#implicit-transactions)\\n- [ChangeSet based persistence](https://github.com/mikro-orm/mikro-orm#changeset-based-persistence)\\n- [Identity map](https://mikro-orm.io/docs/identity-map/)\\n\\n![](https://cdn-images-1.medium.com/max/1024/0*fKozvvTJns0y3w5U.png)\\n\\nYou can read the full [introductory article here](https://medium.com/dailyjs/introducing-mikro-orm-typescript-data-mapper-orm-with-identity-map-9ba58d049e02) (but note that many things have changed since that was written) or [browse through the docs](https://mikro-orm.io/).\\n\\n### Quick summary of 4.x releases\\n\\nBefore we dive into all the things v5, let\u2019s recap what happened in 4.x releases:\\n\\n- [Result cache](https://mikro-orm.io/docs/caching/)\\n- [Automatic transaction context](https://github.com/mikro-orm/mikro-orm/pull/959)\\n- [Nested embeddables](https://mikro-orm.io/docs/embeddables/#nested-embeddables) and many other improvements in this domain\\n- [Using env vars for configuration](https://mikro-orm.io/docs/configuration/#using-environment-variables)\\n\\nBut enough of the history lesson, let\u2019s talk about the future!\\n\\n### Improved type safety\\n\\nLet\u2019s jump right into the most interesting feature \u2013 strict typing (almost) everywhere! `em.create()`, `toJSON()`, `toObject()`, populate, partial loading, and order by hints, all of that (and even more!) is now strictly typed.\\n\\nLet\u2019s check the following example:\\n\\n```ts\\nconst god = em.create(Author, {\\n  name: \'God\', // validates required properties\\n  email: \'god@heaven.io\',\\n  books: [{\\n    title: \'Bible, part 1\',\\n    tags: [{ name: \'old\' }, { name: \'bestseller\' }],\\n  }],\\n}, { persist: true }); // we can enable this globally via `persistOnCreate: true`\\nawait em.flush();\\n\\n// simulate new request\\nem.clear();\\n\\n// `authors` is of type `Loaded<Author, \'books.tags\'>[]`\\nconst authors = await em.find(Author, {}, {\\n  populate: [\'books.tags\'], // populate hint can be inferred from `fields` if not explicitly provided\\n  fields: [\'books.tags.name\'], // strict partial loading with dot notation support\\n  orderBy: { name: \'asc\', books: { tags: { name: \'asc\' } } }, // strict order by with object nesting\\n});\\n\\n// `books` and `tags` will be typed as `LoadedCollection` so we can use safe `$` accessor\\nconsole.log(authors[0].books.$[0].tags.$[0].name);\\nconst dto = wrap(authors[0]).toObject();\\nconsole.log(dto.books[0].tags[0].name); // DTOs are also strictly typed\\n```\\n\\nFirst, we use `em.create()` to build the whole entity graph in a single step. It will validate the payload for both types and optionality. Some properties on the entity might have default values provided via hooks or database functions \u2013 while we might want to define them as required properties, they should act as optional in the context of `em.create()`. To deal with this problem, we can specify such properties that should be considered as optional via `OptionalProps` symbol:\\n\\n```ts\\n@Entity()\\nexport class Author {\\n\\n  // only `name` will be considered as required for `em.create()`\\n  [OptionalProps]?: \'createdAt\' | \'updatedAt\';\\n\\n  @PrimaryKey()\\n  id!: number;\\n\\n  @Property({ defaultRaw: \'current_timestamp()\' })\\n  createdAt!: Date;\\n\\n  @Property({ onUpdate: () => new Date(), length: 3, defaultRaw: \'current_timestamp(3)\' })\\n  updatedAt!: Date;\\n\\n  @Property()\\n  name!: string;\\n\\n}\\n```\\n\\n> Some property names are always considered as optional: `id`, `_id`, `uuid`.\\n\\nThen we load all Author entities, populating their books and the book tags. All of the FindOptions here are strictly typed, moreover, we could even skip the populate hint as it can be inferred from fields option automatically.\\n\\n![](https://cdn-images-1.medium.com/max/600/0*3g12H4O5KrzmQMrk.jpg)\\n\\nWe might still need some type casting for DTOs. The serialized form of an entity can be very unpredictable \u2013 there are many variables that define how an entity will be serialized, e.g. loaded relation vs reference, property serializers, lazy properties, custom entity serializer/`toJSON` method, eager loading, recursion checks, \u2026 Therefore, all relations on the EntityDTO type are considered as loaded, this is mainly done to allow better DX as if we had all relations typed as `Primary<T> | EntityDTO<T>` (e.g. `number | EntityDTO<Book>`), it would be impossible to benefit from intellisense/autosuggestions. Imagine this scenario:\\n\\n```ts\\nconst book = {} as Book;\\nconst dto = wrap(book).toObject(); // EntityDTO<Book>\\n\\n// this is now possible, but with the PK union type, we would need to type cast all the time\\nconst name = dto.author.name;\\n```\\n\\n### Validation improvements\\n\\nAdding on top of the compile-time validation, we also get a runtime validation right before insert queries are fired, to ensure required properties have their values. This is important mainly in mongo, where we don\u2019t have optionality checks on the schema level.\\n\\nWhen we try to use the CLI without installing it locally, we also get a warning. And what if we forget to update some of the ORM packages and ended up with version mismatch and multiple installed core packages? We now validate that too!\\n\\n### Reworked schema diffing\\n\\nSchema diffing has been one of the weakest spots. Often, additional queries were produced or it was even impossible to get to a fully synchronized state.\\n\\nSchema diffing has been completely reworked to address all currently known issues, and adding _a bit more_ on top of that:\\n\\n- Diffing foreign key constraints\\n- Proper index diffing (before we compared just names)\\n- Custom index expressions\\n- Comment diffing\\n- Column length diffing (e.g. `numeric(10,2)` or `varchar(100)`)\\n- Changing primary key types\\n- Schema/namespace diffing (Postgres only)\\n- Automatic down migrations (no SQLite support yet)\\n- Check constraints support (Postgres only)\\n\\n### Smarter migrations\\n\\nIn the production environment, we might want to use compiled migration files. Since v5, this should work almost out of the box, all we need to do is to configure the migrations path accordingly. Executed migrations now ignore the file extension, so we can use both node and ts-node on the same database. This is done in a backward-compatible manner.\\n\\n```ts\\nimport { MikroORM, Utils } from \'@mikro-orm/core\';\\n\\nawait MikroORM.init({\\n  migrations: {\\n    path: \'dist/migrations\',\\n    pathTs: \'src/migrations\',\\n  },\\n  // or alternatively\\n  // migrations: {\\n  //   path: Utils.detectTsNode() ? \'src/migrations\' : \'dist/migrations\',\\n  // },\\n  // ...\\n});\\n```\\n\\nCreating new migration will now automatically save the target schema snapshot into the migrations folder. This snapshot will be then used if we try creating a new migration, instead of using the current database schema. This means that if we try to create new migration before we run the pending ones, we still get the right schema diff (and no migration will be created if no additional changes were made).\\n\\n> Snapshots should be versioned just like the regular migration files.\\n\\n### Auto-flush mode\\n\\n![](https://cdn-images-1.medium.com/max/1024/0*J74FKP7MaZoHO3Al.jpg)\\n\\nUp until now, flushing was always an explicit action. With v5, we can configure the flushing strategy, similarly to how JPA/hibernate work. We have 3 flush modes:\\n\\n- `FlushMode.COMMIT` - The `EntityManager` tries to delay the flush until the current transaction is committed, although it might flush prematurely too.\\n- `FlushMode.AUTO` - This is the default mode, and it flushes the `EntityManager` only if necessary.\\n- `FlushMode.ALWAYS` - Flushes the `EntityManager` before every query.\\n\\nFlushMode.AUTO will try to detect changes on the entity we are querying, and flush if there is an overlap:\\n\\n```ts\\n// querying for author will trigger auto-flush if we have new author persisted\\nconst a1 = new Author(...);\\nem.persist(a1);\\nconst r1 = await em.find(Author, {});\\n\\n// querying author won\'t trigger auto-flush if we have new book, but no changes on author\\nconst b4 = new Book(...);\\nem.persist(b4);\\nconst r2 = await em.find(Author, {});\\n\\n// but querying for book will trigger auto-flush\\nconst r3 = await em.find(Book, {});\\n```\\n\\nMore about flush modes [in the docs](https://mikro-orm.io/docs/unit-of-work/#flush-modes).\\n\\n### Automatic refreshing of loaded entities\\n\\nPreviously, when an entity was loaded and we needed to reload it, providing explicit refresh: true in the options was required. Refreshing of entity also had one problematic side effect \u2013 the entity data (used for computing changesets) were always updated based on the newly loaded entity, hence forgetting the previous state (resulting in possibly lost updates done on the entity before refreshing).\\n\\nNow we always merge the newly loaded data with the current state, and when we see an updated property, we keep the changed value instead. Moreover, for `em.findOne()` with a primary key condition, we try to detect whether it makes sense to reload an entity, by comparing the options and already loaded property names. In this step the `fields` and `populate` options are taken into account to support both partial loading and lazy properties.\\n\\n```ts\\n// first partially load author with `id` and `email` only\\nconst a1 = await em.findOneOrFail(Author, 123, { fields: [\'id\', \'email\'] });\\na1.email = \'lol\'; // let\'s change the email\\n\\n// reloading with same fields won\'t fire the query (as before)\\nconst a2 = await em.findOneOrFail(Author, 123, { fields: [\'email\'] });\\nconsole.log(a1 === a2); // true, same entity instance, no query was fired\\n\\n// reloading with additional fields will work without `refresh: true`\\nconst a3 = await em.findOneOrFail(Author, 123, { fields: [\'id\', \'age\'] });\\nconsole.log(a1 === a3); // true, same entity instance, but updated!\\nconsole.log(a1.age); // new values are loaded\\na1.age = 1000; // let\'s override them\\n\\n// reloading full entity will work without `refresh: true`\\nconst a4 = await em.findOneOrFail(Author, 123, { populate: [\'books\'] });\\nconsole.log(a1 === a4); // true, same entity instance, but updated!\\nconsole.log(a1.termsAccepted); // new values are loaded\\n\\nawait em.flush(); // updates the author with new email and age\\n```\\n\\nFor complex conditions in `em.findOne()` and for any queries via `em.find()`, we always do the query anyway, but now instead of ignoring the data in case such entity was loaded, we merge them in the same manner.\\n\\n```ts\\n// first partially load author entities\\nconst r1 = await em.find(Author, {}, { fields: [\'id\'] });\\nr1[0].email = \'lol\'; // let\'s change one of the emails\\nconsole.log(r1[0].name); // undefined, not loaded\\n\\n// reload full entities - no `refresh: true` needed!\\nconst r2 = await em.find(Author, {});\\nconsole.log(r2[0]); // fully loaded author entity, but `email` is changed to \'lol\'\\nconsole.log(r1[0] === r2[0]); // true, same entity instance, just updated!\\n\\n// flushing will now fire one update query to change the email of one author\\nawait em.flush();\\n```\\n\\n### Seeder package\\n\\nMikroORM v5 now has a new package for seeding your database with initial or testing data. It allows creating entities via the same EntityManager API as usual, adding support for entity factories, and generating fake data via faker (the newly release community version).\\n\\nSee the [seeder docs](https://mikro-orm.io/docs/seeding) for more examples.\\n\\n### Polymorphic embeddables\\n\\nPolymorphic embeddables allow us to define multiple classes for a single embedded property and the right one will be used based on the discriminator column, similar to how single table inheritance works. While this currently works only for embeddables, support for polymorphic entities will be probably added in one of the 5.x releases.\\n\\n```ts\\n@Entity()\\nclass Owner {\\n\\n  @PrimaryKey()\\n  id!: number;\\n\\n  @Property()\\n  name!: string;\\n\\n  @Embedded(() => [Cat, Dog])\\n  pet!: Cat | Dog;\\n\\n}\\n```\\n\\nCheck out the [documentation](https://mikro-orm.io/docs/embeddables/#polymorphic-embeddables) for a complete example.\\n\\nThere are many other small improvements in embeddables, as well as many issues were addressed. Two examples:\\n\\n- Support for many-to-one relations (storing only primary key and being able to populate the relation same as with regular entities)\\n- Support for `onCreate` and `onUpdate` property options\\n\\n### Populating lazy scalar properties\\n\\nPreviously, the only way to populate a lazy scalar property was during the initial load of containing entity. If such entity was already loaded in the identity map (without this property), we needed to refresh its state \u2013 and potentially lose some state. MikroORM v5 allows to populate such properties via `em.populate()` too. Doing so will never override any in-memory changes we might have done on the entity.\\n\\n### Creating references without EntityManager\\n\\nWhen we wanted to create a reference, so an entity that is represented only by its primary key, we always had to have access to the current `EntityManager` instance, as such entity always needed to be managed.\\n\\nThanks to the new helper methods on the Reference class, we can now create entity references without access to `EntityManager`. This can be handy if you want to create a reference from an inside entity constructor:\\n\\n```ts\\n@Entity()\\nexport class Book {\\n\\n  @ManyToOne(() => Author, { wrappedReference: true })\\n  author!: IdentifiedReference<Author>;\\n\\n  constructor(authorId: number) {\\n    this.author = Reference.createFromPK(Author, authorId);\\n  }\\n\\n}\\n```\\n\\n> The `Reference` wrapper is an optional class to allow more type safety over relationships. Alternatively, we can use `Reference.createNakedFromPK()`.\\n\\nThis will create an unmanaged reference, that will be then merged to the `EntityManager` once owning entity gets flushed. Note that before we flush it, methods like `Reference.init()` or `Reference.load()` won\u2019t be available as they require the EntityManager instance.\\n\\n### Smarter `expr` helper\\n\\nThe `expr()` helper can be used to get around strict typing. It was an identity function, doing nothing more than returning its parameter \u2013 all it did was to tell TypeScript the value is actually of a different type (a generic string to be precise).\\n\\nWe can now use the helper in two more ways:\\n\\n- With a callback signature to allow dynamic aliasing of the expression\\n- With an array argument to allow comparing tuples\\n\\n```ts\\nimport { expr } from \'@mikro-orm/core\';\\n\\nconst res1 = await em.find(Book, {\\n  // the type argument is optional, use it to get autocomplete on the entity properties\\n  [expr<Book>([\'price\', \'createdAt\'])]: { $lte: [100, new Date()] },\\n});\\n\\n// will issue query similar to this:\\n// select `b0`.* from `book` as `b0` where (`b0`.`price`, `b0`.`created_at`) <= (?, ?)\\n\\nconst res2 = await em.find(Book, {\\n  // the type argument is optional, use it to get autocomplete on the entity properties\\n  [expr(as => `lower(${as}.name)`)]: \'jon\',\\n});\\n\\n// will issue query similar to this:\\n// select `b0`.* from `book` as `b0` where lower(b0.name) = ?\\n```\\n\\n### Awaitable QueryBuilder\\n\\nQueryBuilder is now aware of its type, and the `getResult()` and `execute()` methods are typed based on it. We can also await the QueryBuilder instance directly, which will automatically execute the QB and return the appropriate response. The QB instance is now typed based on usage of `select`/`insert`/`update`/`delete`/`truncate` methods to one of:\\n\\n- `SelectQueryBuilder` \u2013 awaiting yields array of entities\\n- `CountQueryBuilder` \u2013 awaiting yields number\\n- `InsertQueryBuilder` \u2013 awaiting yields `QueryResult`\\n- `UpdateQueryBuilder` \u2013 awaiting yields `QueryResult`\\n- `DeleteQueryBuilder` \u2013 awaiting yields `QueryResult`\\n- `TruncateQueryBuilder` \u2013 awaiting yields `QueryResult`\\n\\n![](https://cdn-images-1.medium.com/max/798/0*jFsyXtSw1ZzZ9-cD.jpg)\\n\\n```ts\\nconst res1 = await em.createQueryBuilder(Publisher).insert({\\n  name: \'p1\',\\n  type: PublisherType.GLOBAL,\\n});\\n// res1 is of type `QueryResult<Publisher>`\\nconsole.log(res1.insertId);\\n\\nconst res2 = await em.createQueryBuilder(Publisher)\\n  .select(\'*\')\\n  .where({ name: \'p1\' })\\n  .limit(5);\\n// res2 is Publisher[]\\nconsole.log(res2.map(p => p.name));\\n\\nconst res3 = await em.createQueryBuilder(Publisher).count().where({ name: \'p1\' });\\n// res3 is number\\nconsole.log(res3 > 0);\\n\\nconst res4 = await em.createQueryBuilder(Publisher)\\n  .update({ type: PublisherType.LOCAL })\\n  .where({ name: \'p1\' });\\n// res4 is QueryResult<Publisher>\\nconsole.log(res4.affectedRows > 0);\\n\\nconst res5 = await em.createQueryBuilder(Publisher).delete().where({ name: \'p1\' });\\n// res4 is QueryResult<Publisher>\\nconsole.log(res4.affectedRows > 0);\\nexpect(res5.affectedRows > 0).toBe(true); // test the type\\n```\\n\\n### Wildcard schema entities\\n\\nUp until now, we were able to define entities in a specific schema, or without a schema. Such entities then used the schema based on ORM config or `FindOptions`. This allowed us to read entities from a specific schema, but we were missing the power of Unit of Work here.\\n\\nWith v5, entity instances now hold schema name (as part of `WrappedEntity`). Managed entities will have the schema from FindOptions or metadata. Methods that create new entity instances like `em.create()` or `em.getReference()` now have an options parameter to allow setting the schema. We can also use `wrap(entity).getSchema()` and `wrap(entity).setSchema()`.\\n\\nEntities can now specify wildcard schema via `@Entity({ schema: \'*\' })`. That way they will be ignored in SchemaGenerator unless the schema option is specified.\\n\\n- If we specify schema, the entity only exists in that schema\\n- If we define `*` schema, the entity can exist in any schema, always controlled by the parameter\\n- If we skip schema option, the value will be taken from global ORM config\\n\\nMore about this topic can be found [here](https://mikro-orm.io/docs/next/multiple-schemas#wildcard-schema).\\n\\n### Deep assigning of entities\\n\\nAnother weak spot was assigning new values to existing entities. While `wrap().assign()` was originally designed to update a single entity and its values, a lot of users wanted to assign an entity graph, updating relations in a single step too.\\n\\nWith v5, the way how `EntityAssigner` detects what entity should be updated has changed. Assigning a deep entity graph should be possible by default, without any additional options. It works based on matching entity primary keys, so if you want to issue an update for a relationship instead of creating new relation, make sure you first load it and pass down its primary key to the assign helper:\\n\\n```ts\\nconst book = await em.findOneOrFail(Book, 1, { populate: [\'author\'] });\\n\\n// update existing book\'s author\'s name\\nwrap(book).assign({\\n  author: {\\n    id: book.author.id,\\n    name: \'New name...\',\\n  },\\n});\\n```\\n\\nIf we want to always update the entity, even without the entity PK being present in data, we can use `updateByPrimaryKey: false`:\\n\\n```ts\\nconst book = await em.findOneOrFail(Book, 1, { populate: [\'author\'] });\\n\\n// update existing book\'s author\'s name\\nwrap(book).assign({\\n  author: {\\n    name: \'New name...\',\\n  },\\n}, { updateByPrimaryKey: false });\\n```\\n\\nMore examples on this topic can be found [in the docs](https://mikro-orm.io/docs/entity-helper/#updating-deep-entity-graph).\\n\\n### Experimental support for ES modules\\n\\nWhile MikroORM v5 is still compiled and published as CommonJS, we added several improvements that should allow using it with ESM projects too. Namely, we use the `gen-esm-wrapper` package to allow using named imports, and we use one nasty trick to keep dynamic imports instead of compiling them to require statements \u2013 for that we need to use `MIKRO_ORM_DYNAMIC_IMPORTS` env var. This should allow us to use folder-based discovery with ES modules, which was previously not possible.\\n\\n### Other notable changes\\n\\n- Partial loading support (`fields`) for joined loading strategy\\n- `AsyncLocalStorage` used by default in the ``RequestContext`` helper\\n- `onLoad` event (like `onInit`, but allows async and fires only for loaded entities, not references)\\n- Exporting async functions from CLI config\\n- Configurable aliasing strategy for SQL\\n- Allow providing [custom Logger instance](https://mikro-orm.io/docs/logging)\\n- [`persist` option in `em.create()` and `persistOnCreate` global configuration](https://mikro-orm.io/docs/configuration/#persist-created-entities-automatically)\\n- M:N support in entity generator\\n- Support for specifying transaction isolation level\\n- Controlling [where condition for populate hints](https://mikro-orm.io/docs/loading-strategies#population-where-condition)\\n- Revamped [API docs](https://mikro-orm.io/api)\\n- and _many many_ more, see the [full changelog here](https://github.com/mikro-orm/mikro-orm/blob/master/CHANGELOG.md#500-rc2-2022-02-03)\\n\\nAlso be sure to check the [upgrading guide](https://mikro-orm.io/docs/upgrading-v4-to-v5).\\n\\n### What\u2019s next?\\n\\nHere is a list of things I would like to focus on going forward:\\n\\n- allow specifying pivot entity for M:N relations (so we can have additional columns there, but still map it as M:N for reading purposes)\\n- support for database views (or maybe just entities representing SQL expressions)\\n- more drivers \u2013 namely better-sqlite3 and cockroach sounds like low hanging fruit, given knex now supports those natively\\n\\n> _Like_ [_MikroORM_](https://mikro-orm.io/)_? \u2b50\ufe0f_ [_Star it_](https://github.com/mikro-orm/mikro-orm) _on GitHub and share this article with your friends. If you want to support the project financially, you can do so via_ [_GitHub Sponsors_](https://github.com/sponsors/B4nan)_._"},{"id":"mikro-orm-4-1-released","metadata":{"permalink":"/blog/mikro-orm-4-1-released","source":"@site/blog/2020-10-13-mikro-orm-4-1-lets-talk-about-performance.md","title":"MikroORM 4.1: Let\u2019s talk about performance","description":"I just shipped version 4.1 of MikroORM,","date":"2020-10-13T00:00:00.000Z","formattedDate":"October 13, 2020","tags":[{"label":"typescript","permalink":"/blog/tags/typescript"},{"label":"javascript","permalink":"/blog/tags/javascript"},{"label":"node","permalink":"/blog/tags/node"},{"label":"sql","permalink":"/blog/tags/sql"}],"readingTime":2.945,"hasTruncateMarker":true,"authors":[{"name":"Martin Ad\xe1mek","title":"Author of MikroORM","url":"https://github.com/B4nan","imageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4"}],"frontMatter":{"slug":"mikro-orm-4-1-released","title":"MikroORM 4.1: Let\u2019s talk about performance","author":"Martin Ad\xe1mek","authorTitle":"Author of MikroORM","authorURL":"https://github.com/B4nan","authorImageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4","authorTwitter":"B4nan","tags":["typescript","javascript","node","sql"]},"prevItem":{"title":"MikroORM 5: Stricter, Safer, Smarter","permalink":"/blog/mikro-orm-5-released"},"nextItem":{"title":"MikroORM 4: Filling the Gaps","permalink":"/blog/mikro-orm-4-released"}},"content":"I just shipped version 4.1 of [MikroORM](https://github.com/mikro-orm/mikro-orm), \\nthe TypeScript ORM for Node.js, and I feel like this particular release deserves \\na bit more attention than a regular feature release.\\n\\n\x3c!--truncate--\x3e\\n\\n![](https://cdn-images-1.medium.com/max/725/0*R2CETMgg1344gf0V.jpg)\\n\\n### In case you don\u2019t know\u2026\\n\\nIf you never heard of [MikroORM](https://github.com/mikro-orm/mikro-orm), it\u2019s a TypeScript data-mapper ORM with Unit of Work and Identity Map. It supports MongoDB, MySQL, PostgreSQL and SQLite drivers currently. Key features of the ORM are:\\n\\n- [Implicit transactions](https://github.com/mikro-orm/mikro-orm#implicit-transactions)\\n- [ChangeSet based persistence](https://github.com/mikro-orm/mikro-orm#changeset-based-persistence)\\n- [Identity map](https://mikro-orm.io/docs/identity-map/)\\n\\n![](https://cdn-images-1.medium.com/max/1024/0*zPahC74XliMguexT.png)\\n\\nYou can read the full [introductory article here](https://medium.com/dailyjs/introducing-mikro-orm-typescript-data-mapper-orm-with-identity-map-9ba58d049e02) or [browse through the docs](https://mikro-orm.io/).\\n\\n### So what changed?\\n\\nThis release had only one clear goal in mind\u200a\u2014\u200athe performance. It all started with [an issue](https://github.com/mikro-orm/mikro-orm/issues/732) pointing out that flushing 10k entities in a single unit of work is very slow. While this kind of use case was never a target for me, I started to see all the possibilities the Unit of Work pattern offers.\\n\\n### Batch inserts, updates and deletes\\n\\nThe biggest performance killer was the amount of queries\u200a\u2014\u200aeven if the query is as simple and optimised as possible, firing 10k of those will be always quite slow. For inserts and deletes, it was quite trivial to group all the queries. A bit more challenging were the updates\u200a\u2014\u200ato batch those, MikroORM now uses case statements.\\n\\nAs a result, when you now flush changes made to one entity type, only one query per given operation (create/update/delete) will be executed. This brings significant difference, as we are now executing fixed number of queries (in fact the changes are batched in chunks of 300 items).\\n\\n```ts\\nfor (let i = 1; i <= 5; i++) {\\n  const u = new User(`Peter ${i}`, `peter+${i}@foo.bar`);\\n  em.persist(u);\\n}\\n\\nawait em.flush();\\n\\n// insert into `user` (`name`, `email`) values\\n//   (\'Peter 1\', \'peter+1@foo.bar\'),\\n//   (\'Peter 2\', \'peter+2@foo.bar\'),\\n//   (\'Peter 3\', \'peter+3@foo.bar\'),\\n//   (\'Peter 4\', \'peter+4@foo.bar\'),\\n//   (\'Peter 5\', \'peter+5@foo.bar\');\\n```\\n\\n```ts\\nfor (const user of users) {\\n  user.name += \' changed!\';\\n}\\n\\nawait em.flush();\\n\\n// update `user` set\\n//   `name` = case \\n//     when (`id` = 1) then \'Peter 1 changed!\' \\n//     when (`id` = 2) then \'Peter 2 changed!\' \\n//     when (`id` = 3) then \'Peter 3 changed!\' \\n//     when (`id` = 4) then \'Peter 4 changed!\' \\n//     when (`id` = 5) then \'Peter 5 changed!\' \\n//     else `priority` end \\n//   where `id` in (1, 2, 3, 4, 5)\\n```\\n\\n```ts\\nem.remove(users);\\nawait em.flush();\\n\\n// delete from `user` where `id` in (1, 2, 3, 4, 5)\\n```\\n\\n### JIT compilation\\n\\nSecond important change in 4.1 is JIT compilation. Under the hood, MikroORM now first generates simple functions for comparing and hydrating entities, that are tailored to their metadata definition. The main difference is that those generated functions are accessing the object properties directly (e.g. o.name), instead of dynamically (e.g. o[prop.name]), as all the information from metadata are inlined there. This allows V8 to better understand the code so it is able to run it faster.\\n\\n### Results\\n\\nHere are the results for a simple 10k entities benchmark:\\n\\n![](https://cdn-images-1.medium.com/max/1024/1*aROevToSrzcQdPsPzXYnSQ.png)\\n\\nIn average, inserting 10k entities takes around 70ms with sqlite, updates are a tiny bit slower. You can see results for other drivers here: [https://github.com/mikro-orm/benchmark](https://github.com/mikro-orm/benchmark).\\n\\n![](https://cdn-images-1.medium.com/max/400/0*2WaopAkejC3T6213.jpg)\\n\\n### Acknowledgement\\n\\nKudos to [Marc J. Schmidt](https://github.com/marcj), the author of the initial issue, as without his help this would probably never happen, or at least not in near future. Thanks a lot!\\n\\n> _Like_ [_MikroORM_](https://mikro-orm.io/)_? \u2b50\ufe0f_ [_Star it_](https://github.com/mikro-orm/mikro-orm) _on GitHub and share this article with your friends. If you want to support the project financially, you can do so via_ [_GitHub Sponsors_](https://github.com/sponsors/B4nan)_._"},{"id":"mikro-orm-4-released","metadata":{"permalink":"/blog/mikro-orm-4-released","source":"@site/blog/2020-09-08-mikro-orm-4-released.md","title":"MikroORM 4: Filling the Gaps","description":"After 4 months of active development, I am thrilled to announce the release of MikroORM 4. When I started to work on v4, the goal was to make it relatively small release, mainly to drop support for TypeScript 3.6 and Node.js 8, and to split the project into multiple packages, so we can have more fine grained control over the dependencies (mainly because of ts-morph having TS as a runtime dependency).","date":"2020-09-08T00:00:00.000Z","formattedDate":"September 8, 2020","tags":[{"label":"typescript","permalink":"/blog/tags/typescript"},{"label":"javascript","permalink":"/blog/tags/javascript"},{"label":"node","permalink":"/blog/tags/node"},{"label":"sql","permalink":"/blog/tags/sql"}],"readingTime":12.695,"hasTruncateMarker":true,"authors":[{"name":"Martin Ad\xe1mek","title":"Author of MikroORM","url":"https://github.com/B4nan","imageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4"}],"frontMatter":{"slug":"mikro-orm-4-released","title":"MikroORM 4: Filling the Gaps","author":"Martin Ad\xe1mek","authorTitle":"Author of MikroORM","authorURL":"https://github.com/B4nan","authorImageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4","authorTwitter":"B4nan","tags":["typescript","javascript","node","sql"]},"prevItem":{"title":"MikroORM 4.1: Let\u2019s talk about performance","permalink":"/blog/mikro-orm-4-1-released"},"nextItem":{"title":"MikroORM 3: Knex.js, CLI, Schema Updates, Entity Generator and\xa0more\u2026","permalink":"/blog/mikro-orm-3-released"}},"content":"After 4 months of active development, I am thrilled to announce the release of [MikroORM 4](http://github.com/mikro-orm/mikro-orm). When I started to work on v4, the goal was to make it relatively small release, mainly to drop support for TypeScript 3.6 and Node.js 8, and to split the project into multiple packages, so we can have more fine grained control over the dependencies (mainly because of ts-morph having TS as a runtime dependency).\\n\\n> But what a major release would that be, without having a bunch of new features as well, right?\\n\\n\x3c!--truncate--\x3e\\n\\n![Photo by Ryoji Iwata on Unsplash](https://cdn-images-1.medium.com/max/1024/0*JU7VN0bgkL57RnZJ)\\n\\n### In case you don\u2019t know\u2026\\n\\nIf you never heard of [MikroORM](https://github.com/mikro-orm/mikro-orm), it\u2019s a TypeScript data-mapper ORM with Unit of Work and Identity Map. It supports MongoDB, MySQL, PostgreSQL and SQLite drivers currently. Key features of the ORM are:\\n\\n- [Implicit transactions](https://github.com/mikro-orm/mikro-orm#implicit-transactions)\\n- [ChangeSet based persistence](https://github.com/mikro-orm/mikro-orm#changeset-based-persistence)\\n- [Identity map](https://mikro-orm.io/docs/identity-map/)\\n\\n![](https://cdn-images-1.medium.com/max/1024/0*VEfH0Y8e_cMVXad1.png)\\n\\nYou can read the full [introductory article here](https://medium.com/dailyjs/introducing-mikro-orm-typescript-data-mapper-orm-with-identity-map-9ba58d049e02) or [browse through the docs](https://mikro-orm.io/).\\n\\n### Quick summary of 3.x releases\\n\\nBefore I dive into all the things v4, let\u2019s recap the major features that landed in 3.x releases:\\n\\n- [Defining entities via](https://mikro-orm.io/docs/entity-schema)[EntitySchema](https://mikro-orm.io/docs/entity-schema)\\n- [Propagation of changes to m:1/1:1 to inverse sides](https://mikro-orm.io/docs/propagation)\\n- [Transactions in MongoDB](https://mikro-orm.io/docs/usage-with-mongo#transactions)\\n- [Composite primary keys](https://mikro-orm.io/docs/composite-keys)\\n\\n### Monorepo\\n\\nThe first major change I want to talk about is the split into multiple packages. As mentioned above, the biggest motivation for this change was to get rid of TS as a runtime dependency, when it is not needed. Another nice example is knex, which is used as a base layer for SQL driver, but has no meaning for mongodb users. Lastly, it turned out Highlight.js, that was used for query highlighting, is also quite fat and slow, so I ended up writing custom highlighters that are built for CLI and are (almost) dependency free.\\n\\nIn v4, there are 12 packages and 2 highlighters, you install only what you use, and you have control over what is needed in production and what is just a dev dependency. This is especially useful for serverless users, where cold start speeds matter.\\n\\nIt felt natural to offer some shortcuts on the EntityManager and EntityRepository level, so we now have flavours of those classes in place, that offer things like em.execute(sql) or em.aggregate(). To access those driver specific methods, be sure to use the classes from driver packages:\\n\\n```ts\\nimport { EntityManager } from \'@mikro-orm/mysql\'; // or any other SQL driver package\\n\\nconst em: EntityManager;\\nconst qb = await em.createQueryBuilder(\u2026); // or `em.execute()`, `em.getKnex()`, ...\\n```\\n\\n> Database connectors like pg or sqlite3 are now dependencies of the driver packages (e. g. @mikro-orm/sqlite).\\n\\n### Filters\\n\\nProbably the most interesting feature of v4 are [filters](https://mikro-orm.io/docs/filters/), also known as association scopes. They allow you to define data visibility rules, both global and bound to entity. One common application of filters are soft deletes, or automatic tenant conditions.\\n\\n```ts\\n@Entity()\\n@Filter({ name: \'expensive\', cond: { price: { $gt: 1000 } } })\\n@Filter({ name: \'long\', cond: { \'length(text)\': { $gt: 10000 } } })\\n@Filter({ name: \'hasAuthor\', cond: { author: { $ne: null } }, default: true })\\n@Filter({ name: \'writtenBy\', cond: args => ({ author: { name: args.name } }) })\\nexport class Book {\\n  ...\\n}\\n\\nconst books1 = await orm.em.find(Book, {}, {\\n  filters: [\'long\', \'expensive\'],\\n});\\nconst books2 = await orm.em.find(Book, {}, {\\n  filters: { hasAuthor: false, long: true, writtenBy: { name: \'God\' } },\\n});\\n```\\n\\nFilters are applied to those methods of EntityManager: find(), findOne(), findAndCount(), findOneOrFail(), count(), nativeUpdate() and nativeDelete(). Filters can be parametric, the parameter can be also in form of callback (possibly async). You can also make the filter enabled by default.\\n\\n> Filter can be defined at the entity level, dynamically via EM (global filters) or in the ORM configuration.\\n\\n#### Global Filters\\n\\nWe can also register filters dynamically via EntityManager API. We call such filters global. They are enabled by default (unless disabled via last parameter in addFilter() method), and applied to all entities. You can limit the global filter to only specified entities.\\n\\n> _Filters as well as filter params set on the EM will be copied to all its forks._\\n\\n```ts\\n// bound to entity, enabled by default\\nem.addFilter(\'writtenBy\', args => ({ author: args.id }), Book);\\n\\n// global, enabled by default, for all entities\\nem.addFilter(\'tenant\', args => { ... });\\n\\n// global, enabled by default, for only specified entities\\nem.addFilter(\'tenant\', args => { ... }, [Author, Book]);\\n...\\n\\n// set params (probably in some middleware)\\nem.setFilterParams(\'tenant\', { tenantId: 123 });\\nem.setFilterParams(\'writtenBy\', { id: 321 });\\n```\\n\\n### EventSubscribers and flush events\\n\\nAs opposed to regular lifecycle hooks, we can now use [EventSubscriber](https://mikro-orm.io/docs/lifecycle-hooks/#eventsubscriber) to hook to multiple entities or if you do not want to pollute the entity prototype. All methods are optional, if you omit the getSubscribedEntities() method, it means you are subscribing to all entities.\\n\\n```ts\\nimport { EntityName, EventArgs, EventSubscriber, Subscriber } from \'@mikro-orm/core\';\\n\\n@Subscriber()\\nexport class AuthorSubscriber implements EventSubscriber<Author> {\\n\\n  getSubscribedEntities(): EntityName<Author>[] {\\n    return [Author];\\n  }\\n\\n  async afterCreate(args: EventArgs<Author>): Promise<void> {\\n    // ...\\n  }\\n\\n  async afterUpdate(args: EventArgs<Author>): Promise<void> {\\n    // ... \\n  }\\n\\n}\\n```\\n\\n#### Flush events\\n\\nThere is a [special kind of events](https://mikro-orm.io/docs/lifecycle-hooks/#flush-events) executed during the commit phase (flush operation). They are executed before, during and after the flush, and they are not bound to any entity in particular.\\n\\n- beforeFlush is executed before change sets are computed, this is the only event where it is safe to persist new entities.\\n- onFlush is executed after the change sets are computed.\\n- afterFlush is executed as the last step just before the flush call resolves. it will be executed even if there are no changes to be flushed.\\n\\nFlush event args will not contain any entity instance, as they are entity agnostic. They do contain additional reference to the UnitOfWork instance.\\n\\nFollowing example demonstrates the hidden power of flush events\u200a\u2014\u200athey allow to hook into the change set tracking, adjusting what will be persisted and how. Here we try to find a CREATE change set for entity FooBar, and if there is any, we automatically create a new FooBaz entity, connecting it to the FooBar one. This kind of operations was previously impossible, as in regular lifecycle hooks we can only adjust the entity that triggers the event.\\n\\n```ts\\n@Subscriber()\\nexport class FooBarSubscriber implements EventSubscriber {\\n\\n  async onFlush(args: FlushEventArgs): Promise<void> {\\n    const changeSets = args.uow.getChangeSets();\\n    const cs = changeSets.find(cs => cs.type === ChangeSetType.CREATE && cs.entity instanceof FooBar);\\n\\n    if (cs) {\\n      const baz = new FooBaz();\\n      baz.name = \'dynamic\';\\n      cs.entity.baz = baz;\\n      args.uow.computeChangeSet(baz);\\n      args.uow.recomputeSingleChangeSet(cs.entity);\\n    }\\n  }\\n\\n}\\n\\nconst bar = new FooBar();\\nbar.name = \'bar\';\\nawait em.persistAndFlush(bar);\\n```\\n\\n### Joined loading strategy\\n\\nLoading of complex relations now support so called [JOINED strategy](https://mikro-orm.io/docs/loading-strategies/). Its name is quite self-explanatory\u200a\u2014\u200ainstead of the default (SELECT\\\\_IN) strategy, it uses single SQL query and maps the result to multiple entities.\\n\\n```ts\\n// with the default SELECT_IN strategy, following will issue 2 queries\\nconst author = await orm.em.findOne(Author, 1, { populate: [\'books\'] });\\n\\n// select * from author where id = 1;\\n// select * from book where author_id in (1);\\n\\n// we can now use JOINED strategy to use a single query\\nconst author = await orm.em.findOne(Author, 1, { populate: [\'books\'], strategy: LoadStrategy.JOINED });\\n\\n// select a.*, b.* from author a left join book b on b.author_id = a.id where a.id = 1;\\n```\\n\\n### Single Table Inheritance\\n\\n[STI is an inheritance mapping strategy](https://mikro-orm.io/docs/inheritance-mapping/#single-table-inheritance) where all classes of a hierarchy are mapped to a single database table. In order to distinguish which row represents which type in the hierarchy a so-called discriminator column is used.\\n\\n> If no discriminator map is provided, it will be generated automatically.\\n\\nFollowing example defines 3 entities\u200a\u2014\u200athey will all be stored in a single database table called person, with a special column named type, that will be used behind the scenes to know what class should be used to represent given row/entity.\\n\\n```ts\\n@Entity({\\n  discriminatorColumn: \'type\',\\n  discriminatorMap: { person: \'Person\', employee: \'Employee\', owner: \'Owner\' },\\n})\\nexport class Person {\\n  // \u2026\\n}\\n\\n@Entity()\\nexport class Employee extends Person {\\n  // \u2026\\n}\\n\\n@Entity()\\nexport class Owner extends Person {\\n  // \u2026\\n}\\n```\\n\\n### Embeddables\\n\\n[Embeddables](https://mikro-orm.io/docs/embeddables/) are classes which are not entities themselves, but are embedded in entities and can also be queried. You\u2019ll mostly want to use them to reduce duplication or separating concerns. Value objects such as date range or address are the primary use case for this feature.\\n\\n> Embeddables can only contain properties with basic @Property() mapping.\\n\\nFollowing example will result in a single database table, where the address fields will be inlined (with prefix) to the user table.\\n\\n```ts\\n@Entity()\\nexport class User {\\n\\n  @Embedded()\\n  address!: Address;\\n\\n}\\n\\n@Embeddable()\\nexport class Address {\\n  \\n  @Property()\\n  street!: string;\\n\\n  @Property()\\n  postalCode!: string;\\n\\n  @Property()\\n  city!: string;\\n\\n  @Property()\\n  country!: string;\\n\\n}\\n```\\n\\n### Lazy scalar properties\\n\\nIn MikroORM 4, we can mark any property as [lazy: true](https://mikro-orm.io/docs/defining-entities#lazy-scalar-properties) to omit it from the select clause. This can be handy for properties that are too large and you want to have them available only some times, like a full text of an article.\\n\\nWhen we need such value, we can use populate parameter to load it as if it was a reference.\\n\\n> If the entity is already loaded and you need to populate a lazy scalar property, you might need to pass refresh: true in the FindOptions.\\n\\n```ts\\n@Entity()\\nexport class Book {\\n\\n  @Property({ columnType: \'text\', lazy: true })\\n  text: string;\\n\\n}\\n\\nconst b1 = await em.find(Book, 1); // this will omit the `text` property\\nconst b2 = await em.find(Book, 1, { populate: [\'text\'] }); // this will load the `text` property\\n```\\n\\n### Computed Properties\\n\\nAnother small enhancement in entity definition is the [@Formula() decorator](https://mikro-orm.io/docs/defining-entities/#formulas). It can be used to map some SQL snippet to your entity. The SQL fragment can be as complex as you want and even include subselects.\\n\\n```ts\\n@Entity()\\nexport class Box {\\n\\n  @Formula(\'obj_length * obj_height * obj_width\')\\n  objectVolume?: number;\\n\\n}\\n```\\n\\n> Formulas will be added to the select clause automatically. In case you are facing problems with NonUniqueFieldNameException, you can define the formula as a callback that will receive the entity alias in the parameter.\\n\\n### Type-safe references\\n\\nNext feature I would like to mention is rather hidden, and is a bit experimental. In MikroORM 4, all EntityManager and EntityRepository methods for querying entities (e.g. find()) will now return special Loaded type, where we automatically infer what relations are populated. It dynamically adds special get() method to both Reference and Collection instances, that you can use to ensure the relation is loaded on the type level.\\n\\n```ts\\n@Entity()\\nexport class Book {\\n\\n  @PrimaryKey()\\n  id: number;\\n\\n  @ManyToOne(() => Author, { wrappedReference: true })\\n  author: IdentifiedReference<Author, \'id\'>;\\n\\n  @ManyToOne(() => Publisher, { wrappedReference: true })\\n  publisher: IdentifiedReference<Publisher, \'id\'>;\\n\\n  @ManyToMany(() => BookTag)\\n  tags = new Collection<BookTag>(this);\\n    \\n}\\n```\\n\\n```ts\\n// will return `Loaded<Book, \'publisher\' | \'tags\' >`\\nconst book = await orm.em.findOne(Book, 1, { populate: [\'publisher\', \'tags\'] });\\n\\n// the `Book.publisher.get()` will be available as we explicitly populated that relation\\nconsole.log(book.publisher.get().name);\\nconsole.log(book.publisher.$.name); // we can also use the `$` alias\\n\\n// on the other hand, `Book.author` was not populated, so trying to access `get()` will fail to compile\\nconsole.log(book.author.get().name); // fails with `TS2339: Property \'get\' does not exist on type \'IdentifiedReference\'`\\n\\n// we can also use it on collections\\nconsole.log(book.tags.get().map(t => t.name)); // `get()` will return array of items\\n```\\n\\n### QueryBuilder improvements\\n\\nThere have been quite a lot of small adjustments in QueryBuilder, to name a few things:\\n\\n- support for subqueries and qb.ref()\\n- using sql snippets with qb.raw()\\n- pagination support via subselects (QueryFlag.PAGINATE)\\n- update & delete queries with auto-joining\\n\\nHere are few examples of those features in action:\\n\\n```ts\\nconst qb = em.createQueryBuilder(Book);\\nqb.update({ price: qb.raw(\'price + 1\') }).where({ uuid: \'123\' });\\n\\n// update `book` set `price` = price + 1 where `uuid_pk` = ?\'\\n```\\n\\n```ts\\n// following example assumes that there is a virtual (persist: false) property\\n// on `Author` entity named `booksTotal`\\n\\nconst qb1 = em.createQueryBuilder(Book, \'b\');\\nqb1.count(\'b.uuid\', true).where({ author: qb1.ref(\'a.id\') });\\nconst qb2 = em.createQueryBuilder(Author, \'a\');\\nqb2.select([\'*\', qb1.as(\'Author.booksTotal\')]).orderBy({ booksTotal: \'desc\' });\\n\\n// select `a`.*, (select count(distinct `b`.`uuid_pk`) as `count` from `book` as `b` where `b`.`author_id` = `a`.`id`) as `books_total` \\n// from `author` as `a` \\n// order by `books_total` desc\\n```\\n\\n```ts\\n// following example assumes that there is a virtual (persist: false) property\\n// on `Author` entity named `booksTotal`\\n\\nconst knex = em.getKnex();\\nconst qb1 = em.createQueryBuilder(Book, \'b\').count(\'b.uuid\', true).where({ author: knex.ref(\'a.id\') }).getKnexQuery();\\nconst qb2 = em.createQueryBuilder(Author, \'a\');\\nqb2.select(\'*\').withSubQuery(qb1, \'a.booksTotal\').where({ \'a.booksTotal\': { $in: [1, 2, 3] } });\\n\\n// select `a`.* \\n// from `author` as `a`\\n// where (select count(distinct `b`.`uuid_pk`) as `count` from `book` as `b` where `b`.`author_id` = `a`.`id`) in (?, ?, ?)\\n```\\n\\n```ts\\nconst qb = em.createQueryBuilder(Publisher);\\nqb.update({ name: \'test 123\' }).where({ $or: [{ books: { author: 123 } }, { books: { title: \'book\' } }] });\\n\\n// update `publisher` set `name` = ? \\n// where `id` in (select `e0`.`id` from (\\n//   select distinct `e0`.`id` from `publisher` as `e0` left join `book` as `e1` on `e0`.`id` = `e1`.`publisher_id` where (`e1`.`author_id` = ? or `e1`.`title` = ?)\\n// ) as `e0`)\\n```\\n\\n### And many many more\u2026\\n\\n- em.begin/commit/rollback() methods are back\\n- using file globs for discovery (\\\\*\\\\*/\\\\*.entity.ts)\\n- custom driver exceptions (UniqueConstraintViolationException, \u2026)\\n- adding items to not-initialized collections\\n- bulk deletes and other performance improvements\\n- inference of custom repository type (EntityRepositoryType)\\n- [property serializers](https://mikro-orm.io/docs/serializing#property-serializers)\\n\\nSee the [changelog](https://github.com/mikro-orm/mikro-orm/blob/master/CHANGELOG.md) for full list of new features and fixes.\\n\\n#### More example integrations\\n\\n- Koa: [https://github.com/mikro-orm/koa-ts-example-app](https://github.com/mikro-orm/koa-ts-example-app)\\n- GraphQL: [https://github.com/driescroons/mikro-orm-graphql-example](https://github.com/driescroons/mikro-orm-graphql-example)\\n- Serverless: [https://github.com/thomaschaaf/serverless-mikro-orm-example-app](https://github.com/thomaschaaf/serverless-mikro-orm-example-app)\\n\\n### Upgrading\\n\\nFor smooth upgrading, read the full [upgrading guide](https://mikro-orm.io/docs/upgrading-v3-to-v4). Here are few notable breaking changes:\\n\\n- Default metadata provider is ReflectMetadataProvider, to use ts-morph, you need to install it from @mikro-orm/reflection and explicitly provide it in the ORM configuration. If you want to use ReflectMetadataProvider, be sure to see the [list of its limitations](https://mikro-orm.io/docs/metadata-providers/#limitations-and-requirements).\\n- TsMorphMetadataProvider now uses \\\\*.d.ts files in production mode, so be sure to enable them in your tsconfig.json.\\n- @mikro-orm/core package is not dependent on knex, and therefore cannot provide methods like createQueryBuilder()\u200a\u2014\u200ainstead, those methods exist on SqlEntityManager. You can import it from the driver package, e.g. import { EntityManager } from \'@mikro-orm/mysql;.\\n- To use CLI, you need to install @mikro-orm/cli package.\\n- When using folder based discovery, the options entitiesDirs and entitiesDirsTs are now removed in favour of entities and entitiesTs. You can now mix entity references with folders and file globs, negative globs are also supported.\\n- For Nest.js users, there is a new [@mikro-orm/nestjs](https://github.com/mikro-orm/nestjs) package, which is a fork of the [nestjs-mikro-orm](https://github.com/dario1985/nestjs-mikro-orm) module with changes needed for   \\nMikroORM 4.\\n\\n### What\u2019s next?\\n\\nHere are some features I\u2019d like to work on in the near future:\\n\\n- Improved schema diffing\\n- ts-morph reflection via custom TS compiler plugin\\n- Query caching\\n- MS SQL Server support\\n\\n### WDYT?\\n\\nSo this is MikroORM 4, what do you think about it? What features or changes would you like to see next? Or what part of the documentation should be improved and how?\\n\\n> _Like_ [_MikroORM_](https://mikro-orm.io/)_? \u2b50\ufe0f_ [_Star it_](https://github.com/mikro-orm/mikro-orm) _on GitHub and share this article with your friends. If you want to support the project financially, you can do so via_ [_GitHub Sponsors_](https://github.com/sponsors/B4nan)_._"},{"id":"mikro-orm-3-released","metadata":{"permalink":"/blog/mikro-orm-3-released","source":"@site/blog/2020-01-16-mikro-orm-3-released.md","title":"MikroORM 3: Knex.js, CLI, Schema Updates, Entity Generator and\xa0more\u2026","description":"New major version of the TypeScript ORM has been released, read about its new features and breaking changes.","date":"2020-01-16T00:00:00.000Z","formattedDate":"January 16, 2020","tags":[{"label":"typescript","permalink":"/blog/tags/typescript"},{"label":"javascript","permalink":"/blog/tags/javascript"},{"label":"node","permalink":"/blog/tags/node"},{"label":"sql","permalink":"/blog/tags/sql"}],"readingTime":10.52,"hasTruncateMarker":true,"authors":[{"name":"Martin Ad\xe1mek","title":"Author of MikroORM","url":"https://github.com/B4nan","imageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4"}],"frontMatter":{"slug":"mikro-orm-3-released","title":"MikroORM 3: Knex.js, CLI, Schema Updates, Entity Generator and\xa0more\u2026","author":"Martin Ad\xe1mek","authorTitle":"Author of MikroORM","authorURL":"https://github.com/B4nan","authorImageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4","authorTwitter":"B4nan","tags":["typescript","javascript","node","sql"]},"prevItem":{"title":"MikroORM 4: Filling the Gaps","permalink":"/blog/mikro-orm-4-released"},"nextItem":{"title":"Handling Transactions and Concurrency in MikroORM","permalink":"/blog/handling-transactions-and-concurrency-in-mikroorm"}},"content":"New major version of the TypeScript ORM has been released, read about its new features and breaking changes.\\n\\n\x3c!--truncate--\x3e\\n\\n### In case you don\u2019t know\u2026\\n\\nIf you never heard of [MikroORM](https://github.com/mikro-orm/mikro-orm), it\u2019s a TypeScript data-mapper ORM with Unit of Work and Identity Map. It supports MongoDB, MySQL, PostgreSQL and SQLite drivers currently. Key features of the ORM are:\\n\\n- [Implicit transactions](https://github.com/mikro-orm/mikro-orm#implicit-transactions)\\n- [ChangeSet based persistence](https://github.com/mikro-orm/mikro-orm#changeset-based-persistence)\\n- [Identity map](https://mikro-orm.io/docs/identity-map/)\\n\\n![](https://cdn-images-1.medium.com/max/1024/0*0eZmw4DceSltEEQh.png)\\n\\nYou can read the full [introductory article here](https://medium.com/dailyjs/introducing-mikro-orm-typescript-data-mapper-orm-with-identity-map-9ba58d049e02) or [browse through the docs](https://mikro-orm.io).\\n\\n### Integrated Knex.js\\n\\nYou probably know Knex.js already, but if you don\u2019t, it is a \u201cbatteries included\u201d SQL query builder for **Postgres** , **MSSQL** , **MySQL** , **MariaDB** , **SQLite3** , **Oracle** , and **Amazon Redshift** designed to be flexible, portable, and fun to use.\\n\\n![](https://cdn-images-1.medium.com/max/649/0*FHWIwC9WTwl2hkQ7.png)\\n\\nKnex.js is now used as both a query builder and a query runner for all SQL drivers. This allows to simplify SQL driver implementations as well as brings some new possibilities.\\n\\n#### Using Knex.js\\n\\nYou can access configured knex instance via qb.getKnexQuery() method. Then you can execute it via the Connection.execute() and map the results via EntityManager.map().\\n\\n```typescript\\nconst qb = orm.em.createQueryBuilder(Author);\\nqb.update({ name: \'test 123\', type: PublisherType.GLOBAL }).where({ id: 123, type: PublisherType.LOCAL });\\nconst knex = qb.getKnexQuery(); // instance of Knex\' QueryBuilder\\n// do what ever you need with `knex`\\nconst res = await orm.em.getConnection().execute(knex);\\nconst entities = res.map(a => orm.em.map(Author, a));\\nconsole.log(entities); // Author[]\\n```\\n\\nYou can also get clear and configured knex instance from the connection via getKnex() method. As this method is not available on the base Connection class, you will need to either manually type cast the connection to AbstractSqlConnection (or the actual implementation you are using, e.g. MySqlConnection), or provide correct driver type hint to your EntityManager instance, which will be then automatically inferred in em.getConnection() method.\\n\\n> Driver and connection implementations are not directly exported from mikro-orm module. You can import them from mikro-orm/dist (e.g. import { PostgreSqlDriver } from \'mikro-orm/dist/drivers/PostgreSqlDriver\').\\n\\n```typescript\\nconst conn = orm.em.getConnection() as AbstractSqlConnection;\\n// you can make sure the `em` is correctly typed to `EntityManager<AbstractSqlDriver>`\\n// or one of its implementations:\\n// const em: EntityManager<AbstractSqlDriver> = orm.em;\\nconst knex = conn.getKnex();\\n// do what ever you need with `knex`\\nconst res = await knex;\\n```\\n\\n#### Connection Pooling\\n\\nWith Knex.js used as a query runner, support for connection pooling is finally available. [Tarn.js](https://github.com/vincit/tarn.js) is used for this internally, using connection pool with min: 2, max: 10 for the MySQL and PG libraries, and a single connection for sqlite3 by default. Use pool option to change this when initializing the ORM.\\n\\n```typescript\\nconst orm = await MikroORM.init({\\n  entities: [Author, Book],\\n  dbName: \'my-db-name\',\\n  pool: { min: 10, max: 20 }, // see https://github.com/vincit/tarn.js#usage for other pool options\\n});\\n```\\n\\n#### More SQL Drivers?\\n\\nOne of the strongest reasons to integrate Knex.js was that it allows to simplify and unify SQL drivers and opens doors for implementing new SQL drivers. Knex.js currently supports (apart from those currently supported by MikroORM): MSSQL, Oracle and Amazon Redshift.\\n\\nThanks to AbstractSqlDriver and AbstractSqlConnection classes it should be fairly simple to implement them. I am open for PRs for those drivers, as I would like to focus on developing new ORM features mainly, instead of learning new SQL dialects I have never used. I will be happy to assist to anybody interested\u200a\u2014\u200afeel free to reach me out either via Slack, email or GitHub issues.\\n\\n### Simplified Entity Definition\\n\\nNow it is no longer needed to merge entities with IEntity interface, that was polluting entity\'s interface with internal methods. New interfaces IdentifiedEntity\\\\<T\\\\>, UuidEntity\\\\<T\\\\> and MongoEntity\\\\<T\\\\> are introduced, that should be implemented by entities. They are not adding any new properties or methods, keeping the entity\'s interface clean.\\n\\nIEntity interface has been renamed to AnyEntity\\\\<T, PK\\\\> and it no longer has public methods like toJSON(), toObject() or init(). One can use wrap() method provided by ORM that will enhance property type when needed with those methods (e.g. await wrap(book.author).init()). To keep all methods available on the entity, you can still use interface merging with WrappedEntity\\\\<T, PK\\\\> that both extends AnyEntity\\\\<T, PK\\\\> and defines all those methods.\\n\\nYou will need to mark the entity by implementing one of \\\\*Entity interfaces:\\n\\n- IdEntity\\\\<T\\\\> for numeric/string PK on id property (id: number)\\n- UuidEntity\\\\<T\\\\> for string PK on uuid property (uuid: string)\\n- MongoEntity\\\\<T\\\\> for mongo, where id: string and \\\\_id: ObjectId are required\\n- AnyEntity\\\\<T, PK\\\\> for other possible properties (fill the PK property name to PK parameter, e.g.: AnyEntity\\\\<Book, \'myPrimaryProperty\'\\\\>\')\\n\\n```typescript\\n@Entity()\\nexport class User implements IdEntity<User> {\\n\\n  @PrimaryKey()\\n  id!: number;\\n\\n  @Property()\\n  name!: string;\\n\\n  @OneToOne()\\n  address?: Address;\\n\\n  @ManyToMany()\\n  cars = new Collection<Car>(this);\\n\\n  constructor(name: string) {\\n    this.name = name;\\n  }\\n\\n}\\n```\\n\\nTo keep all public methods that were part of IEntity interface in v2, you can use [WrappedEntity\\\\<T, PK\\\\> via interface merging](https://mikro-orm.io/docs/defining-entities#using-wrappedentity-interface).\\n\\n### Nested Queries\\n\\nSQL driver now support nested where and orderBy conditions. This means that you can query by properties of a relationship and the relation will be automatically joined for you. They are available both in EntityManager and QueryBuilder APIs.\\n\\n```typescript\\nconst book = await orm.em.findOne(Book, {\\n  author: {\\n    name: \'Jon Snow\',\\n    address: {\\n      street: \'Downing Street\',\\n    },\\n  },\\n}, [\'author.address\']);\\n\\nconsole.log(book.author.name); // \'Jon Snow\'\\nconsole.log(book.author.address.street); // \'Downing Street\'\\n```\\n\\n### Strict Typing of Queries\\n\\nPreviously the where parameter of EntityManager\u2019s find methods (find(), findOne(), count()) was weakly typed. It allowed users to pass pretty much anything there.\\n\\nNow the query is strictly typed, only entity properties and operators can be used and the type of property value is also checked.\\n\\n```typescript\\n// correct query\\nem.find(Author, {\\n  favouriteBook: {\\n    author: { name: \'...\' },\\n  },\\n  age: { $gte: 40 }, // operators are also supported\\n});\\n\\n// 2 errors will be reported here\\nem.find(Author, {\\n  favouriteBook: {\\n    author: { born: \'test\' }, // string instead of Date\\n  },\\n  age: { $lte: \'nan\' }, // string instead of number\\n});\\n```\\n\\n### Improved Schema Generator\\n\\nSchemaGenerator now supports creating, updating and dropping the schema. You can either get the SQL queries as array of strings or directly run them on the database.\\n\\n> Always check the generated SQL first before running it.\\n\\nThere is also new columnType property attribute you can use to specify the database specific column type explicitly.\\n\\n### Migrations\\n\\n![](https://cdn-images-1.medium.com/max/628/0*b3RWZY_ROCrJs3RE.jpeg)\\n\\nBetter way to handle schema updates than using the SchemaGenerator directly is to use Migrations. MikroORM 3 has [integrated support for migrations](https://mikro-orm.io/docs/migrations) via [umzug](https://github.com/sequelize/umzug). It allows you to generate migrations with current schema differences.\\n\\nBy default, each migration will be all executed inside a transaction, and all of them will be wrapped in one master transaction, so if one of them fails, everything will be rolled back.\\n\\n### Generating Entities from Current Database\\n\\nAs a counterpart to the SchemaGenerator that propagates changes in your entities to the database schema, there is now [EntityGenerator](https://mikro-orm.io/docs/entity-generator) to help you with reverse engineering current database schema and creating entities based on it.\\n\\nIt supports basic entity definition including ManyToOne and OneToOne relationships. Currently ManyToMany will be generated as additional entity with two ManyToOne relations and you will need to refactor this yourself.\\n\\nWhile it can help a lot, there is quite a lot of room for improvement. In future I would like to implement proper support for ManyToMany relations as well for enums and indexes. Another possible extension would be to allow editing existing entities (syncing them with current schema).\\n\\n### CLI\\n\\nWhile you can use SchemaGenerator and EntityGenerator manually, much easier way is to use [new CLI tool](https://mikro-orm.io/docs/installation#setting-up-the-commandline-tool). Simply create configuration file in root directory or add its path to package.json. TypeScript files are also supported via ts-node:\\n\\n```json\\n{\\n  \\"name\\": \\"your-app\\",\\n  \\"dependencies\\": { ... },\\n  \\"mikro-orm\\": {\\n    \\"useTsNode\\": true,\\n    \\"configPaths\\": [\\n      \\"./src/mikro-orm.config.ts\\",\\n      \\"./dist/mikro-orm.config.js\\"\\n    ]\\n  }\\n}\\n```\\n\\nNow you can use the CLI with help of [npx](https://github.com/npm/npx):\\n\\n```sh\\n$ npx mikro-orm\\nUsage: mikro-orm <command> [options]\\n\\nCommands:\\n  mikro-orm cache:clear             Clear metadata cache\\n  mikro-orm cache:generate          Generate metadata cache for production\\n  mikro-orm generate-entities       Generate entities based on current database\\n                                    schema\\n  mikro-orm database:import <file>  Imports the SQL file to the database\\n  mikro-orm schema:create           Create database schema based on current\\n                                    metadata\\n  mikro-orm schema:drop             Drop database schema based on current\\n                                    metadata\\n  mikro-orm schema:update           Update database schema based on current\\n                                    metadata\\n  mikro-orm migration:create        Create new migration with current schema\\n                                    diff\\n  mikro-orm migration:up            Migrate up to the latest version\\n  mikro-orm migration:down          Migrate one step down\\n  mikro-orm migration:list          List all executed migrations\\n  mikro-orm migration:pending       List all pending migrations\\n  mikro-orm debug                   Debug CLI configuration\\n\\nOptions:\\n  -v, --version  Show version number                                   [boolean]\\n  -h, --help     Show help                                             [boolean]\\n\\nExamples:\\n  mikro-orm schema:update --run  Runs schema synchronization\\n```\\n\\nTo verify your setup, you can use the mikro-orm debug command. Once you have it configured properly, you can also re-use it when initializing the ORM:\\n\\n```\\n// when no options parameter is provided, CLI config will be used\\nconst orm = await MikroORM.init();\\n```\\n\\n### Custom Mapping Types\\n\\n![](https://cdn-images-1.medium.com/max/500/0*zAn0BtH_iz7b8Ywj.jpg)\\n\\nWith [Custom Types](https://mikro-orm.io/docs/custom-types/) we can now enhance how the database value will be represented in the ORM. You can define custom types by extending Type abstract class, it has 4 optional methods:\\n\\n- convertToDatabaseValue(value: any, platform: Platform): any\\n\\nConverts a value from its JS representation to its database representation of this type. By default returns unchanged value.\\n\\n- convertToJSValue(value: any, platform: Platform): any\\n\\nConverts a value from its database representation to its JS representation of this type. By default returns unchanged value.\\n\\n- toJSON(value: any, platform: Platform): any\\n\\nConverts a value from its JS representation to its serialized JSON form of this type. By default converts to the database value.\\n\\n- getColumnType(prop: EntityProperty, platform: Platform): string\\n\\nGets the SQL declaration snippet for a field of this type. By default returns columnType of given property.\\n\\nHere is a simplified version of DateType that is already present in the ORM:\\n\\n```typescript\\nimport { Type, Platform, EntityProperty, ValidationError } from \'mikro-orm\';\\n\\nexport class DateType extends Type {\\n\\n  convertToDatabaseValue(value: any, platform: Platform): any {\\n    return value.toISOString().substr(0, 10);\\n  }\\n\\n  convertToJSValue(value: any, platform: Platform): any {\\n    return new Date(value);\\n  }\\n\\n  getColumnType(): string {\\n    return \'date\';\\n  }\\n\\n}\\n```\\n\\n```typescript\\n@Entity()\\nexport class FooBar implements IdEntity<FooBar> {\\n  \\n  @PrimaryKey()\\n  id!: number;\\n  \\n  @Property({ type: DateType })\\n  born?: Date;\\n\\n}\\n```\\n\\n### And Many More\u2026\\n\\nThere are many more new features, see the [changelog](https://github.com/mikro-orm/mikro-orm/blob/master/CHANGELOG.md) to read the full list. Here are few of them worth mentioning:\\n\\n- [Improved support for References](https://mikro-orm.io/docs/entity-references/)\\n- [Native Enum support](https://mikro-orm.io/docs/defining-entities/#enums)\\n- [em.findAndCount()](https://mikro-orm.io/docs/entity-manager#fetching-paginated-results) and [em.findOneOrFail()](https://mikro-orm.io/docs/entity-manager#handling-not-found-entities) methods\\n- [ReflectMetadataProvider](https://mikro-orm.io/docs/metadata-providers/#reflectmetadataprovider) as a fast alternative to ts-morph reflection\\n- Improved logging with query highlighting\\n- [Support for bundling via Webpack](https://mikro-orm.io/docs/deployment/#deploy-a-bundle-of-entities-and-dependencies-with-webpack)\\n- Eager loading\\n- [Read Connections](https://mikro-orm.io/docs/read-connections)\\n- More strict entity definition validation\\n\\n### Notable Breaking Changes\\n\\nHere is a short list of breaking changes. You can see the full list in the docs: [https://mikro-orm.io/docs/upgrading-v2-to-v3/](https://mikro-orm.io/docs/upgrading-v2-to-v3/).\\n\\n#### Auto-flushing Disabled by Default\\n\\n> _If you had_ _autoFlush: false in your ORM configuration before, you can now remove this line, no changes are needed in your app._\\n\\nDefault value for autoFlush is now false. That means you need to call em.flush() yourself to persist changes into database. You can still change this via ORM\'s options to ease the transition but generally it is not recommended as it can cause unwanted small transactions being created around each persist.\\n\\n```typescript\\norm.em.persist(new Entity()); // no auto-flushing by default\\nawait orm.em.flush();\\nawait orm.em.persist(new Entity(), true); // you can still use second parameter to auto-flush\\n```\\n\\n#### Transactions API\\n\\nTransactions now require using em.transactional() method, previous methods beginTransaction/commit/rollback are now removed.\\n\\n```typescript\\nawait orm.em.transactional(async _em => {\\n  //... do some work\\n  const user = new User(...);\\n  user.name = \'George\';\\n  _em.persistLater(user);\\n});\\n```\\n\\n### Making it a bit more Professional\u2026\\n\\nNot a big deal, but probably worth mentioning\u200a\u2014\u200aMikroORM\u2019s repository has been transferred to new [MikroORM GitHub Organization](https://github.com/mikro-orm) and the website is now moved to [mikro-orm.io](https://mikro-orm.io). Old links should be properly redirected, if you find some 404, please let me know thru GitHub issues!\\n\\nWebsite has also been redesigned\u200a\u2014\u200anow it is built with Docusaurus (v2) and provides fulltext search by Algolia. The docs are now also [versioned](https://mikro-orm.io/versions).\\n\\n[Check it out!](https://mikro-orm.io)\\n\\n![](https://cdn-images-1.medium.com/max/1024/1*2pdwLgyPZNltJQ_2j8poSQ.png)\\n\\n### What\u2019s next?\\n\\nHere are some features I am planning to work in the near future:\\n\\n- Composite primary keys\\n- Transactions in MongoDB\\n- Complex hydration of joined result sets\\n- Slow query log\\n- M:N support in entity generator\\n\\nThere are also some interesting suggestion in the Github issues, like [Dataloader integration](https://github.com/mikro-orm/mikro-orm/issues/266).\\n\\n#### WDYT?\\n\\nSo that is MikroORM 3, what do you think about it? What features or changes would you like to see next? Or what part of the documentation should be improved and how?\\n\\n> _Like_ [_MikroORM_](https://mikro-orm.io)_? \u2b50\ufe0f_ [_Star it_](https://github.com/mikro-orm/mikro-orm) _on GitHub and share this article with your friends._\\n\\n* * *"},{"id":"handling-transactions-and-concurrency-in-mikroorm","metadata":{"permalink":"/blog/handling-transactions-and-concurrency-in-mikroorm","source":"@site/blog/2019-06-18-handling-transactions-and-concurrency-in-mikroorm.md","title":"Handling Transactions and Concurrency in MikroORM","description":"How to handle transactions and concurrency with ease.","date":"2019-06-18T00:00:00.000Z","formattedDate":"June 18, 2019","tags":[{"label":"typescript","permalink":"/blog/tags/typescript"},{"label":"javascript","permalink":"/blog/tags/javascript"},{"label":"node","permalink":"/blog/tags/node"},{"label":"sql","permalink":"/blog/tags/sql"}],"readingTime":9.705,"hasTruncateMarker":true,"authors":[{"name":"Martin Ad\xe1mek","title":"Author of MikroORM","url":"https://github.com/B4nan","imageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4"}],"frontMatter":{"slug":"handling-transactions-and-concurrency-in-mikroorm","title":"Handling Transactions and Concurrency in MikroORM","author":"Martin Ad\xe1mek","authorTitle":"Author of MikroORM","authorURL":"https://github.com/B4nan","authorImageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4","authorTwitter":"B4nan","tags":["typescript","javascript","node","sql"]},"prevItem":{"title":"MikroORM 3: Knex.js, CLI, Schema Updates, Entity Generator and\xa0more\u2026","permalink":"/blog/mikro-orm-3-released"},"nextItem":{"title":"Introducing MikroORM, TypeScript data-mapper ORM with Identity Map","permalink":"/blog/introducing-mikroorm-typescript-data-mapper-orm-with-identity-map"}},"content":"How to handle transactions and concurrency with ease.\\n\\n\x3c!--truncate--\x3e\\n\\n## Note about persisting\\n\\nThere are 2 methods we should first describe to understand how persisting works in MikroORM: `em.persist()` and `em.flush()`.\\n\\n`em.persist(entity, flush?: boolean)` is used to mark new entities for future persisting. It will make the entity managed by given `EntityManager` and once `flush` will be called, it will be written to the database. Second boolean parameter can be used to invoke `flush` immediately. Its default value is configurable via `autoFlush` option.\\n\\n> Default value of `autoFlush` is currently set to `true`, which will change in upcoming major release. Users are encouraged to either set `autoFlush` to `false` or use `em.persistLater()` (equal to `em.persist(entity, false)`) and `em.persistAndFlush()` methods instead. Every time persisting is mentioned in this article, it is with `autoFlush` set to `false` in mind.\\n\\nTo understand `flush`, lets first define what managed entity is: An entity is managed if it\u2019s fetched from the database (via `em.find()`, `em.findOne()` or via other managed entity) or registered as new through `em.persist()`.\\n\\n`em.flush()` will go through all managed entities, compute appropriate change sets and perform according database queries. As an entity loaded from database becomes managed automatically, you do not have to call `persist` on those, and `flush` is enough to update them.\\n\\n![](https://cdn-images-1.medium.com/max/1600/0*Eo5JP9abOfPV24Uf.jpg)\\n\\n## Transaction demarcation\\n\\nTransaction demarcation is the task of defining your transaction boundaries. For the most part, MikroORM already takes care of proper transaction demarcation for you: All the write operations (INSERT/UPDATE/DELETE) are queued until `em.flush()` is invoked which wraps all of these changes in a single transaction. However, MikroORM also allows (and encourages) you to take over and control transaction demarcation yourself.\\n\\n### Approach 1: Implicitly\\n\\nThe first approach is to use the implicit transaction handling provided by the MikroORM `EntityManager`. Given the following code snippet, without any explicit transaction demarcation:\\n\\n```typescript\\nconst user = new User();\\nuser.name = \'George\';\\nawait orm.em.persistAndFlush(user);\\n```\\n\\nSince we do not do any custom transaction demarcation in the above code, `em.flush()` will begin and commit/rollback a transaction. This is sufficient if all the data manipulation that is part of a unit of work happens through the domain model and thus the ORM\u200a\u2014\u200ain other words, unless you run some write queries manually, via `QueryBuilder`, or use one of `em.nativeInsert/Update/Delete` helpers.\\n\\nHere is a bit more complex example where multiple entities are involved:\\n\\n```typescript\\nconst author = await orm.em.findOne(Author, id, [\'books.tags\', \'books.publisher\']);\\nauthor.books[0].title = \'New book name\';\\nauthor.books[0].tags[0].name = \'old\';\\nauthor.books[0].tags.add(new BookTag(\'sale\'));\\nauthor.books[0].publisher.name = \'New publisher name\';\\nawait orm.em.flush();\\n```\\n\\nWe load one author by id, all his books and their tags as well as their publisher. For simplicity, let\u2019s assume the author has one book associated, which has one book tag and one publisher.\\n\\nThen we update multiple things on book of that author, editing name of the tag, adding new one, and changing publisher\u2019s name. As we are working with already managed entities (retrieved from `EntityManager`), we can simply `flush` without needing to `persist` those entities.\\n\\nThe `flush` call here will compute all differences and run database queries accordingly. They will all be encapsulated in a transaction, as you can see from following list of fired queries:\\n\\n```sql\\nSTART TRANSACTION;\\nINSERT INTO `book_tag` (`name`) VALUES (?);\\nUPDATE `book` SET `title` = ? WHERE `id` = ?;\\nDELETE FROM `book_to_book_tag` WHERE `book_id` = ?;\\nINSERT INTO `book_to_book_tag` (`book_id`, `book_tag_id`) VALUES (?, ?);\\nINSERT INTO `book_to_book_tag` (`book_id`, `book_tag_id`) VALUES (?, ?);\\nUPDATE `publisher` SET `name` = ? WHERE `id` = ?;\\nUPDATE `book_tag` SET `name` = ? WHERE `id` = ?;\\nCOMMIT;\\n```\\n\\n### Approach 2: Explicitly\\n\\nThe explicit alternative is to use the transactions API directly to control the boundaries. The code then looks like this:\\n\\n```typescript\\nawait orm.em.beginTransaction();\\n\\ntry {\\n  //... do some work\\n  const user = new User(...);\\n  user.name = \'George\';\\n  await orm.em.persistAndFlush(user);\\n  await orm.em.commit();\\n} catch (e) {\\n  await orm.em.rollback();\\n  throw e;\\n}\\n```\\n\\nExplicit transaction demarcation is required when you want to include custom DBAL operations in a unit of work (e.g. when firing native SQL UPDATE queries) or when you want to make use of some methods of the `EntityManager` API that require an active transaction (e.g. locking)\u200a\u2014\u200asuch methods will throw a `ValidationError` to inform you of that requirement.\\n\\nA more convenient alternative for explicit transaction demarcation is to use `em.transactional(cb)`. It will automatically start the transaction, execute your asynchronous callback and commit it. In case of an exception during those operations, the transaction will be automatically rolled back and the exception will be re-thrown. An example that is functionally equivalent to the previously shown code looks as follows:\\n\\n```typescript\\nawait orm.em.transactional(async _em => {\\n  //... do some work\\n  const user = new User(...);\\n  user.name = \'George\';\\n  _em.persistLater(user);\\n});\\n```\\n\\nIn the callback parameter, you will get forked `EntityManager` that will contain a copy of the current Identity Map. You should use this copy instead of the parent one for all queries inside the transaction. It will be flushed prior to transaction commit.\\n\\n### Exception Handling\\n\\nWhen using _implicit_ transaction demarcation and an exception occurs during `em.flush()`, the transaction is automatically rolled back.\\n\\nWhen using _explicit_ transaction demarcation and an exception occurs, the transaction should be rolled back immediately as demonstrated in the example above. Users are encouraged to use `em.transactional(cb)` which will handle that automatically.\\n\\nAs a result of this procedure, all previously managed or removed instances of the `EntityManager` become detached. The state of the detached objects will be the state at the point at which the transaction was rolled back. The state of the objects is in no way rolled back and thus the objects are now out of sync with the database. The application can continue to use the detached objects, knowing that their state is potentially no longer accurate.\\n\\nIf you intend to start another unit of work after an exception has occurred you should do that with a new `EntityManager`. Simply use `em.fork()` to obtain fresh copy with cleared identity map.\\n\\n![](https://cdn-images-1.medium.com/max/1600/0*D4B7hf_Up9bc9wzg.jpg)\\n\\n## Concurrency and\xa0locking\\n\\n### Why we need concurrency control?\\n\\nIf transactions are executed _serially_ (one at a time), no transaction concurrency exists. However, if concurrent transactions with interleaving operations are allowed, you may easily run into one of those problems:\\n\\n1.  The lost update problem\\n2.  The dirty read problem\\n3.  The incorrect summary problem\\n\\nTake a look at [this article](https://www.includehelp.com/dbms/concurrency-and-problem-due-to-concurrency.aspx) for in-depth explanation of those.\\n\\nTo mitigate those problems, MikroORM offers support for Pessimistic and Optimistic locking strategies natively. This allows you to take very fine-grained control over what kind of locking is required for your entities in your application.\\n\\n### Optimistic Locking\\n\\nDatabase transactions are fine for concurrency control during a single request. However, a database transaction should not span across requests, the so-called \u201cuser think time\u201d. Therefore a long-running \u201cbusiness transaction\u201d that spans multiple requests needs to involve several database transactions. Thus, database transactions alone can no longer control concurrency during such a long-running business transaction. Concurrency control becomes the partial responsibility of the application itself.\\n\\nMikroORM has integrated support for automatic optimistic locking via a version field. In this approach any entity that should be protected against concurrent modifications during long-running business transactions gets a version field that is either a simple number or a Date (timestamp). When changes to such an entity are persisted at the end of a long-running conversation the version of the entity is compared to the version in the database and if they don\u2019t match, a `ValidationError` is thrown, indicating that the entity has been modified by someone else already.\\n\\nTo define a version field, simply use `@Property` decorator with `version` flag set to `true`. Only `Date` and `number` types are allowed.\\n\\n```typescript\\nexport class User {\\n  // ...\\n  @Property({ version: true })\\n  version: number;\\n  // ...\\n}\\n```\\n\\n```typescript\\nexport class Book {\\n  // ...\\n  @Property({ version: true })\\n  version: Date;\\n  // ...\\n}\\n```\\n\\n> Version numbers (not timestamps) should be preferred as they can not potentially conflict in a highly concurrent environment, unlike timestamps where this is a possibility, depending on the resolution of the timestamp on the particular database platform.\\n\\nWhen a version conflict is encountered during `em.flush()`, a `ValidationError` is thrown and the active transaction rolled back (or marked for rollback). This exception can be caught and handled. Potential responses to a `ValidationError` are to present the conflict to the user or to refresh or reload objects in a new transaction and then retrying the transaction.\\n\\nThe time between showing an update form and actually modifying the entity can in the worst scenario be as long as your applications session timeout. If changes happen to the entity in that time frame you want to know directly when retrieving the entity that you will hit an optimistic locking exception.\\n\\nYou can always verify the version of an entity during a request either when calling `em.findOne()`:\\n\\n```typescript\\nconst theEntityId = 1;\\nconst expectedVersion = 184;\\n\\ntry {\\n  const entity = await orm.em.findOne(User, theEntityId, { lockMode: LockMode.OPTIMISTIC, lockVersion: expectedVersion });\\n  // do the work\\n  await orm.em.flush();\\n} catch (e) {\\n  console.log(\'Sorry, but someone else has already changed this entity. Please apply the changes again!\');\\n}\\n```\\n\\nOr you can use `em.lock()` to find out:\\n\\n```typescript\\nconst theEntityId = 1;\\nconst expectedVersion = 184;\\nconst entity = await orm.em.findOne(User, theEntityId);\\n\\ntry {\\n  // assert version\\n  await orm.em.lock(entity, LockMode.OPTIMISTIC, expectedVersion);\\n} catch (e) {\\n  console.log(\'Sorry, but someone else has already changed this entity. Please apply the changes again!\');\\n}\\n```\\n\\nUsing optimistic locking correctly, you **have** to pass the version as an additional parameter when updating entity. See following example:\\n\\n```typescript\\nconst res = await fetch(\'api.example.com/book/123\');\\nconst book = res.json();\\nconsole.log(book.version); // prints the current version\\n\\n// user does some changes and calls the PUT handler\\nconst changes = { title: \'new title\' };\\nawait fetch(\'api.example.com/book/123\', {\\n  method: \'PUT\',\\n  body: {\\n    ...changes,\\n    version: book.version,\\n  },\\n});\\n```\\n\\n```typescript\\n// GET /book/:id\\nasync findOne(req, res) {\\n  const book = await this.em.findOne(Book, +req.query.id);\\n  res.json(book);\\n}\\n\\n// PUT /book/:id\\nasync update(req, res) {\\n  const book = await this.em.findOne(Book, +req.query.id, { lockMode: LockMode.OPTIMISTIC, lockVersion: req.body.version });\\n  book.assign(req.body);\\n  await this.em.flush();\\n\\n  res.json(book);\\n}\\n```\\n\\nYour frontend app loads an entity from API, the response includes the version property. User makes some changes and fires PUT request back to the API, with version field included in the payload. The PUT handler of the API then reads the version and passes it to the `em.findOne()` call.\\n\\n## Pessimistic Locking\\n\\nMikroORM supports Pessimistic Locking at the database level. Every Entity can be part of a pessimistic lock, there is no special metadata required to use this feature. Pessimistic Locking requires active transaction, so you will have to use explicit transaction demarcation.\\n\\nMikroORM currently supports two pessimistic lock modes:\\n\\n*   Pessimistic Write (`LockMode.PESSIMISTIC_WRITE`), locks the underlying database rows for concurrent Read and Write Operations.\\n*   Pessimistic Read (`LockMode.PESSIMISTIC_READ`), locks other concurrent requests that attempt to update or lock rows in write mode.\\n\\nYou can use pessimistic locks in three different scenarios:\\n\\n1.  Using `em.findOne(className, id, { lockMode  })`\\n2.  Using `em.lock(entity, lockMode)`\\n3.  Using `QueryBuilder.setLockMode(lockMode)`\\n\\nThis is how it looks like in action:\\n\\n```typescript\\nawait em.transactional(async _em => {\\n  await _em.findOne(Author, id, { lockMode: LockMode.PESSIMISTIC_WRITE });\\n});\\n\\n// START TRANSACTION\\n// SELECT `e0`.* FROM `author` AS `e0` WHERE `e0`.`id` = ? FOR UPDATE\\n// COMMIT\\n```\\n\\n```typescript\\nconst author = orm.em.findOne(Author, id);\\n// ...\\nawait orm.em.transactional(async em => {\\n  await em.lock(author, LockMode.PESSIMISTIC_READ);\\n});\\n\\n// SELECT `e0`.* FROM `author` AS `e0` WHERE `e0`.`id` = ?\\n// START TRANSACTION\\n// SELECT 1 FROM `author` AS `e0` WHERE `e0`.`id` = ? LOCK IN SHARE MODE\\n// COMMIT\\n```\\n\\n> Like [MikroORM](https://b4nan.github.io/mikro-orm/)? \u2b50\ufe0f [Star it](https://github.com/mikro-orm/mikro-orm) on GitHub and share this article with your friends."},{"id":"introducing-mikroorm-typescript-data-mapper-orm-with-identity-map","metadata":{"permalink":"/blog/introducing-mikroorm-typescript-data-mapper-orm-with-identity-map","source":"@site/blog/2019-04-08-introducing-mikroorm-typescript-data-mapper-orm-with-identity-map.md","title":"Introducing MikroORM, TypeScript data-mapper ORM with Identity Map","description":"This might be the ORM you\u2019ve been looking for\u2026","date":"2019-04-08T00:00:00.000Z","formattedDate":"April 8, 2019","tags":[{"label":"typescript","permalink":"/blog/tags/typescript"},{"label":"javascript","permalink":"/blog/tags/javascript"},{"label":"node","permalink":"/blog/tags/node"},{"label":"oop","permalink":"/blog/tags/oop"}],"readingTime":9.3,"hasTruncateMarker":true,"authors":[{"name":"Martin Ad\xe1mek","title":"Author of MikroORM","url":"https://github.com/B4nan","imageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4"}],"frontMatter":{"slug":"introducing-mikroorm-typescript-data-mapper-orm-with-identity-map","title":"Introducing MikroORM, TypeScript data-mapper ORM with Identity Map","author":"Martin Ad\xe1mek","authorTitle":"Author of MikroORM","authorURL":"https://github.com/B4nan","authorImageURL":"https://avatars1.githubusercontent.com/u/615580?s=460&v=4","authorTwitter":"B4nan","tags":["typescript","javascript","node","oop"]},"prevItem":{"title":"Handling Transactions and Concurrency in MikroORM","permalink":"/blog/handling-transactions-and-concurrency-in-mikroorm"}},"content":"This might be the ORM you\u2019ve been looking for\u2026\\n\\n\x3c!--truncate--\x3e\\n\\n## Motivation\\n\\nDuring my early days at university, I remember how quickly I fell in love with object oriented programming and the concepts of [Object-relational mapping](http://hibernate.org/orm/what-is-an-orm/) and [Domain Driven Design](https://stackoverflow.com/questions/1222392/can-someone-explain-domain-driven-design-ddd-in-plain-english-please/1222488#1222488). Back then, I was mainly a PHP programmer (_while we did a lot of Java/Hibernate at school_), so a natural choice for me was to start using [Doctrine](https://www.doctrine-project.org/).\\n\\nA few years ago, when I switched from PHP to Node.js (_and later to TypeScript_), I was really confused. How come there is nothing similar to Hibernate or Doctrine in the JavaScript world? About a year ago, I finally came across [TypeORM](https://typeorm.io/), and when I read this line in the readme I thought I found what I was looking for:\\n\\n> TypeORM is highly influenced by other ORMs, such as [Hibernate](http://hibernate.org/orm/), [Doctrine](http://www.doctrine-project.org/) and [Entity Framework](https://www.asp.net/entity-framework).\\n\\n![](https://cdn-images-1.medium.com/max/800/1*gWvTBke0c8BFLGR8u_5zSg.jpeg)\\n\\nI started playing with it immediately, but I got disappointed very quickly. No Identity Map that would keep track of all loaded entities. No Unit of Work that would handle transaction isolation. No unified API for references with very strange support for [accessing just the identifier without populating the entity](https://typeorm.io/#/relations-faq/how-to-use-relation-id-without-joining-relation), MongoDB driver (_which I was aiming to use_) was experimental and I had a lot problems setting it up. After a few days of struggle, I went away from it.\\n\\nBy that time, I started to think about writing something myself. And that is how [**MikroORM**](https://github.com/mikro-orm/mikro-orm) started!\\n\\n![](https://cdn-images-1.medium.com/max/800/1*f8phoYPnVRkwuV1wynXz_A.png)\\n\\n> [MikroORM](https://github.com/mikro-orm/mikro-orm) is TypeScript ORM for Node.js based on Data Mapper, Unit of Work and Identity Map patterns.\\n\\nCurrently it supports **MongoDB**, **MySQL, PostgreSQL** and **SQLite** databases, but more can be supported via [custom drivers right now](https://b4nan.github.io/mikro-orm/custom-driver/). It has first class TypeScript support, while staying back compatible with [Vanilla JavaScript](https://b4nan.github.io/mikro-orm/usage-with-js/).\\n\\n## Installation\\n\\nFirst install the module via `yarn` or `npm` and do not forget to install the database driver as well. Next you will need to enable support for [decorators](https://www.typescriptlang.org/docs/handbook/decorators.html)  \\nin `tsconfig.json` via `experimentalDecorators` flag. Then call `MikroORM.init` as part of bootstrapping your application.\\n\\nLast step is to provide forked `EntityManager` for each request, so it will have its own unique [Identity Map](https://b4nan.github.io/mikro-orm/identity-map/). To do so, you can use `EntityManager.fork()` method. Another way, that is more [DI](https://medium.freecodecamp.org/a-quick-intro-to-dependency-injection-what-it-is-and-when-to-use-it-7578c84fa88f) friendly, is to create new [request context](https://b4nan.github.io/mikro-orm/identity-map/#request-context) for each request, which will use some [dark magic](https://github.com/nodejs/node/blob/master/doc/api/async_hooks.md) in the background to always pick the right `EntityManager` for you.\\n\\n```sh\\n# using yarn\\n$ yarn add mikro-orm mongodb # for mongo\\n$ yarn add mikro-orm mysql2  # for mysql\\n$ yarn add mikro-orm pg      # for postgresql\\n$ yarn add mikro-orm sqlite  # for sqlite\\n\\n# or npm\\n$ npm i -s mikro-orm mongodb # for mongo\\n$ npm i -s mikro-orm mysql2  # for mysql\\n$ npm i -s mikro-orm pg      # for postgresql\\n$ npm i -s mikro-orm sqlite  # for sqlite\\n```\\n\\n```json\\n{\\n  \\"compilerOptions\\": {\\n    \\"module\\": \\"commonjs\\",\\n    \\"target\\": \\"es2017\\",\\n    \\"moduleResolution\\": \\"node\\",\\n    \\"declaration\\": true,\\n    \\"strict\\": true,\\n    \\"strictPropertyInitialization\\": false,\\n    \\"experimentalDecorators\\": true\\n  }\\n}\\n```\\n\\n```typescript\\nconst orm = await MikroORM.init({\\n  entities: [Author, Book, BookTag],\\n  dbName: \'my-db-name\',\\n  clientUrl: \'...\', // defaults to \'mongodb://127.0.0.1:27017\' for mongodb driver\\n  type: \'mongo\', // one of \'mysql\', \'postgresql\', \'sqlite\', defaults to \'mongo\'\\n  autoFlush: false, // read more here: https://b4nan.github.io/mikro-orm/unit-of-work/\\n});\\n\\nconsole.log(orm.em); // access EntityManager via `em` property\\n```\\n\\n```typescript\\nconst app = express();\\n\\napp.use((req, res, next) => {\\n  req.em = orm.em.fork(); // save the fork to `req` object\\n});\\n\\napp.get(\'/books\', async (req, res) => {\\n  const books = await req.em.find(Book); // use the fork via `req.em`\\n});\\n```\\n\\n```typescript\\nconst app = express();\\n\\n// by providing request context, creating forked EntityManager will be handled automatically\\napp.use((req, res, next) => {\\n  RequestContext.create(orm.em, next);\\n});\\n```\\n\\n## Defining entities\\n\\nTo [define an entity](https://b4nan.github.io/mikro-orm/defining-entities/), simply create a class and decorate it. Here is an example of `Book` entity defined for MongoDB driver:\\n\\n```typescript\\n\\nimport { ObjectID } from \'mongodb\';\\nimport { Collection, Entity, IEntity, ManyToMany, ManyToOne, PrimaryKey, Property } from \'mikro-orm\';\\nimport { Author, BookTag, Publisher } from \'.\';\\n\\n@Entity()\\nexport class Book {\\n\\n  @PrimaryKey()\\n  _id: ObjectID;\\n\\n  @Property()\\n  createdAt = new Date();\\n\\n  @Property({ onUpdate: () => new Date() })\\n  updatedAt = new Date();\\n\\n  @Property()\\n  title: string;\\n\\n  @ManyToOne()\\n  author: Author;\\n\\n  @ManyToOne()\\n  publisher: Publisher;\\n\\n  @ManyToMany({ entity: () => BookTag, inversedBy: \'books\' })\\n  tags = new Collection<BookTag>(this);\\n\\n  constructor(title: string, author: Author) {\\n    this.title = title;\\n    this.author = author;\\n  }\\n\\n}\\n\\nexport interface Book extends IEntity<string> { }\\n```\\n\\nAs you can see, it\u2019s pretty simple and straightforward. Entities are simple JavaScript objects (_so called POJO_), decorated with `@Entity` decorator (_for TypeScript_), or accompanied with [schema definition object](https://b4nan.github.io/mikro-orm/usage-with-js/) (_for vanilla JavaScript_). No real restrictions are made, you do not have to extend any base class, you are more than welcome to [use entity constructors](https://b4nan.github.io/mikro-orm/entity-constructors/) for specifying required parameters to always keep the entity in valid state. The only requirement is to define the primary key property.\\n\\n![](https://cdn-images-1.medium.com/max/800/1*NlsF497deWAYi5FSijW9NQ.jpeg)\\n\\nYou might be curious about the last line with `Book` as an interface. This is called [interface merging](https://www.typescriptlang.org/docs/handbook/declaration-merging.html#merging-interfaces) and it is there to let TypeScript know the entity will have some extra API methods (like `init()` or `isInitialized()`) available as it will be monkey-patched during discovery process. More about this can be found [in the docs](https://b4nan.github.io/mikro-orm/defining-entities/).\\n\\n## Persisting entities with EntityManager\\n\\nTo save entity state to database, you need to [persist it](https://b4nan.github.io/mikro-orm/entity-manager/). Persist determines whether to use `insert` or `update` and computes appropriate change-set. As a result, only changed fields will be updated in database.\\n\\n[MikroORM](https://b4nan.github.io/mikro-orm/) comes with support for [cascading persist and remove operations](https://b4nan.github.io/mikro-orm/cascading/). Cascade persist is enabled by default, which means that by persisting an entity, all referenced entities will be automatically persisted too.\\n\\n```typescript\\nconst author = new Author(\'Jon Snow\', \'snow@wall.st\');\\nauthor.born = new Date();\\n\\nconst publisher = new Publisher(\'7K publisher\');\\n\\nconst book1 = new Book(\'My Life on The Wall, part 1\', author);\\nbook1.publisher = publisher;\\nconst book2 = new Book(\'My Life on The Wall, part 2\', author);\\nbook2.publisher = publisher;\\nconst book3 = new Book(\'My Life on The Wall, part 3\', author);\\nbook3.publisher = publisher;\\n\\n// just persist books, author and publisher will be automatically cascade persisted\\nawait orm.em.persistAndFlush([book1, book2, book3]);\\n\\n// or one by one\\norm.em.persistLater(book1);\\norm.em.persistLater(book2);\\norm.em.persistLater(book3);\\nawait orm.em.flush(); // flush everything to database at once\\n```\\n\\n![](https://cdn-images-1.medium.com/max/800/1*x6Oqsg8I4y4Z3FiWtn1ORA.gif)\\n\\n## Fetching entities\\n\\nTo fetch entities from database you can use `find()` and `findOne()` methods of `EntityManager`:\\n\\n```typescript\\n// find all authors with name matching \'Jon\', and populate all of their books\\nconst authors = await orm.em.find(Author, { name: /Jon/ }, [\'books\']); \\n\\nfor (const author of authors) {\\n  console.log(author.name); // Jon Snow\\n\\n  for (const book of author.books) {\\n    console.log(book.title); // initialized\\n    console.log(book.author.isInitialized()); // true\\n    console.log(book.author.id);\\n    console.log(book.author.name); // Jon Snow\\n    console.log(book.publisher); // just reference\\n    console.log(book.publisher.isInitialized()); // false\\n    console.log(book.publisher.id);\\n    console.log(book.publisher.name); // undefined\\n  }\\n}\\n```\\n\\nMore convenient way of fetching entities from database is by using `EntityRepository`, that carries the entity name so you do not have to pass it to every `find` and `findOne` calls:\\n\\n```typescript\\nimport { QueryOrder } from \'mikro-orm\';\\n\\nconst booksRepository = orm.em.getRepository(Book);\\n\\n// with sorting, limit and offset parameters, populating author references\\nconst books = await booksRepository.find({ author: \'...\' }, [\'author\'], { title: QueryOrder.DESC }, 2, 1);\\n\\n// or with options object\\nconst books = await booksRepository.find({ author: \'...\' }, { \\n  populate: [\'author\'],\\n  limit: 1,\\n  offset: 2,\\n  sort: { title: QueryOrder.DESC },\\n});\\n\\nconsole.log(books); // Book[]\\n```\\n\\n## Working with references\\n\\nEntity associations are mapped to entity references. Reference is an entity that has at least the identifier (_primary key_). This reference is stored in the Identity Map so you will get the same object reference when fetching the same document from database.\\n\\nThanks to this concept, MikroORM offers unified API for accessing entity references, regardless of whether the entity is initialized or not. Even if you do not populate an association, there will be its reference with primary key set. You can call `await entity.init()` to initialize the entity. This will trigger database call and populate itself, keeping the same reference to entity object in identity map.\\n\\n```typescript\\nconst book = orm.em.findOne(Book, \'...\');\\nconsole.log(book.author); // reference with ID only, instance of Author entity\\n\\n// this will get the same reference as we already have in `book.author`\\nconst author = orm.em.getReference(Author, book.author.id);\\nconsole.log(author.id); // accessing the id will not trigger any db call\\nconsole.log(author.isInitialized()); // false\\nconsole.log(author.name); // undefined\\nconsole.log(author === book.author); // true\\n\\n// this will trigger db call, we could also use `orm.em.findOne(Author, author.id)` to do the same\\nawait author.init(); \\nconsole.log(author.isInitialized()); // true\\nconsole.log(author.name); // defined\\n```\\n\\n![](https://cdn-images-1.medium.com/max/800/1*PY1hb2ufRhbevdIFt9jR1g.jpeg)\\n\\n## Identity Map and Unit of\xa0Work\\n\\n[MikroORM](https://b4nan.github.io/mikro-orm/) uses the Identity Map in background to track objects. This means that whenever you fetch entity via `EntityManager`, MikroORM will keep a reference to it inside its `UnitOfWork`, and will always return the same instance of it, even if you query one entity via different properties. This also means you can compare entities via strict equality operators (`===` and\xa0`!==`):\\n\\n```typescript\\nconst authorRepository = orm.em.getRepository(Author);\\nconst jon = await authorRepository.findOne({ name: \'Jon Snow\' }, [\'books\']);\\nconst jon2 = await authorRepository.findOne({ email: \'snow@wall.st\' });\\nconst authors = await authorRepository.findAll([\'books\']);\\n\\n// identity map in action\\nconsole.log(jon === authors[0]); // true\\nconsole.log(jon === jon2); // true\\n\\n// as we always have one instance, books will be populated also here\\nconsole.log(jon2.books);\\n```\\n\\nAnother benefit of Identity Map is that this allows us to skip some database calls. When you try to load an already managed entity by its identifier, the one from Identity Map will be returned, without querying the database.\\n\\nThe power of Unit of Work is in running all queries inside a batch and wrapped inside a transaction (_if supported by given driver_). This approach is usually more performant as opposed to firing queries from various places.\\n\\n## Collections\\n\\n`OneToMany` and `ManyToMany` collections are stored in a `Collection` wrapper. It implements iterator so you can use `for of` loop to iterate through it.\\n\\nAnother way to access collection items is to use bracket syntax like when you access array items. Keep in mind that this approach will not check if the collection is initialized, while using `get` method will throw error in this case.\\n\\n```typescript\\n// find author and populate his books collection\\nconst author = orm.em.findOne(Author, \'...\', [\'books\']);\\n\\nfor (const book of author.books) {\\n  console.log(book); // instance of Book\\n}\\n\\nauthor.books.add(book);\\nconsole.log(author.books.contains(book)); // true\\nauthor.books.remove(book);\\nconsole.log(author.books.contains(book)); // false\\nauthor.books.add(book);\\nconsole.log(author.books.count()); // 1\\nconsole.log(author.books.getItems()); // Book[]\\nconsole.log(author.books.getIdentifiers()); // array of primary keys of all items\\nauthor.books.removeAll();\\n```\\n\\nMore information about collections can be found [in the docs](https://b4nan.github.io/mikro-orm/collections/).\\n\\n## What\u2019s next?\\n\\nSo you read through the whole article, got here and still not satisfied? There are more articles to come (beginning with integration manual for popular frameworks like [Express](https://expressjs.com/) or [NestJS](https://nestjs.com/)), but you can take a look at some advanced features covered in docs right now:\\n\\n*   [Smart nested populate](https://b4nan.github.io/mikro-orm/nested-populate/)\\n*   [Smart query conditions](https://b4nan.github.io/mikro-orm/query-conditions/)\\n*   [Updating entity values with `IEntity.assign()`](https://b4nan.github.io/mikro-orm/entity-helper/) \\n*   [Property validation](https://b4nan.github.io/mikro-orm/property-validation/)\\n*   [Lifecycle hooks](https://b4nan.github.io/mikro-orm/lifecycle-hooks/)\\n*   [Naming strategy](https://b4nan.github.io/mikro-orm/naming-strategy/)\\n*   [Usage with NestJS](https://b4nan.github.io/mikro-orm/usage-with-nestjs/)\\n*   [Usage with JavaScript](https://b4nan.github.io/mikro-orm/usage-with-js/)\\n\\n![](https://cdn-images-1.medium.com/max/800/1*4877k4Hq9dPdtmvg9hnGFA.jpeg)\\n\\nTo start playing with [MikroORM](https://github.com/mikro-orm/mikro-orm), go through [quick start](https://github.com/mikro-orm/mikro-orm#quick-start) and [read the docs](https://b4nan.github.io/mikro-orm/). You can also take a look at [example integrations with some popular frameworks](http://github.com/mikro-orm/mikro-orm-examples).\\n\\n> _Like_ [_MikroORM_](https://b4nan.github.io/mikro-orm/)_? \u2b50\ufe0f_ [_Star it_](https://github.com/mikro-orm/mikro-orm) _on GitHub and share this article with your friends._\\n\\n_This article was originally published on Medium: https://medium.com/dailyjs/introducing-mikro-orm-typescript-data-mapper-orm-with-identity-map-9ba58d049e02_"}]}')}}]);